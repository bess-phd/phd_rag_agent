{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cdab5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-identity in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.26.0b1)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-identity) (1.38.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-identity) (46.0.3)\n",
      "Requirement already satisfied: msal>=1.30.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-identity) (1.35.0b1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-identity) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from azure-identity) (4.15.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in /home/codespace/.local/lib/python3.12/site-packages (from azure-core>=1.31.0->azure-identity) (2.32.5)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity) (2.23)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity) (2.10.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# 1️⃣ Install / Import Packages\n",
    "# =============================================\n",
    "!pip install --pre azure-ai-projects>=2.0.0b1\n",
    "!pip install azure-identity\n",
    "\n",
    "import os\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "851e13e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DefaultAzureCredential failed to retrieve a token from the included credentials.\n",
      "Attempted credentials:\n",
      "\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\n",
      "Visit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.\n",
      "\tWorkloadIdentityCredential: WorkloadIdentityCredential authentication unavailable. The workload options are not fully configured. See the troubleshooting guide for more information: https://aka.ms/azsdk/python/identity/workloadidentitycredential/troubleshoot. Missing required arguments: 'tenant_id', 'client_id', 'token_file_path'.\n",
      "\tManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no response from the IMDS endpoint. Token request error: (invalid_request) Identity not found\n",
      "\tSharedTokenCacheCredential: SharedTokenCacheCredential authentication unavailable. No accounts were found in the cache.\n",
      "\tVisualStudioCodeCredential: VisualStudioCodeCredential requires the 'azure-identity-broker' package to be installed. You must also ensure you have the Azure Resources extension installed and have signed in to Azure via Visual Studio Code.\n",
      "\tAzureCliCredential: Please run 'az login' to set up an account\n",
      "\tAzurePowerShellCredential: PowerShell is not installed\n",
      "\tAzureDeveloperCliCredential: Azure Developer CLI could not be found. Please visit https://aka.ms/azure-dev for installation instructions and then,once installed, authenticate to your Azure account using 'azd auth login'.\n",
      "\tBrokerCredential: InteractiveBrowserBrokerCredential unavailable. The 'azure-identity-broker' package is required to use brokered authentication.\n",
      "To mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.\n"
     ]
    },
    {
     "ename": "ClientAuthenticationError",
     "evalue": "DefaultAzureCredential failed to retrieve a token from the included credentials.\nAttempted credentials:\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\nVisit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.\n\tWorkloadIdentityCredential: WorkloadIdentityCredential authentication unavailable. The workload options are not fully configured. See the troubleshooting guide for more information: https://aka.ms/azsdk/python/identity/workloadidentitycredential/troubleshoot. Missing required arguments: 'tenant_id', 'client_id', 'token_file_path'.\n\tManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no response from the IMDS endpoint. Token request error: (invalid_request) Identity not found\n\tSharedTokenCacheCredential: SharedTokenCacheCredential authentication unavailable. No accounts were found in the cache.\n\tVisualStudioCodeCredential: VisualStudioCodeCredential requires the 'azure-identity-broker' package to be installed. You must also ensure you have the Azure Resources extension installed and have signed in to Azure via Visual Studio Code.\n\tAzureCliCredential: Please run 'az login' to set up an account\n\tAzurePowerShellCredential: PowerShell is not installed\n\tAzureDeveloperCliCredential: Azure Developer CLI could not be found. Please visit https://aka.ms/azure-dev for installation instructions and then,once installed, authenticate to your Azure account using 'azd auth login'.\n\tBrokerCredential: InteractiveBrowserBrokerCredential unavailable. The 'azure-identity-broker' package is required to use brokered authentication.\nTo mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientAuthenticationError\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mazure\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01midentity\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DefaultAzureCredential\n\u001b[32m      3\u001b[39m cred = DefaultAzureCredential()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m token = \u001b[43mcred\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_token\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://management.azure.com/.default\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mToken acquired:\u001b[39m\u001b[33m\"\u001b[39m, token.token[:\u001b[32m20\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# prints first 20 chars\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/azure/identity/_credentials/default.py:344\u001b[39m, in \u001b[36mDefaultAzureCredential.get_token\u001b[39m\u001b[34m(self, claims, tenant_id, *scopes, **kwargs)\u001b[39m\n\u001b[32m    342\u001b[39m within_dac.set(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     token = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclaims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclaims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    346\u001b[39m     within_dac.set(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/azure/identity/_credentials/chained.py:159\u001b[39m, in \u001b[36mChainedTokenCredential.get_token\u001b[39m\u001b[34m(self, claims, tenant_id, enable_cae, *scopes, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m message = (\n\u001b[32m    152\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\n\u001b[32m    153\u001b[39m     + \u001b[33m\"\u001b[39m\u001b[33m failed to retrieve a token from the included credentials.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttps://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m )\n\u001b[32m    158\u001b[39m _LOGGER.warning(message)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ClientAuthenticationError(message=message)\n",
      "\u001b[31mClientAuthenticationError\u001b[39m: DefaultAzureCredential failed to retrieve a token from the included credentials.\nAttempted credentials:\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\nVisit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.\n\tWorkloadIdentityCredential: WorkloadIdentityCredential authentication unavailable. The workload options are not fully configured. See the troubleshooting guide for more information: https://aka.ms/azsdk/python/identity/workloadidentitycredential/troubleshoot. Missing required arguments: 'tenant_id', 'client_id', 'token_file_path'.\n\tManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no response from the IMDS endpoint. Token request error: (invalid_request) Identity not found\n\tSharedTokenCacheCredential: SharedTokenCacheCredential authentication unavailable. No accounts were found in the cache.\n\tVisualStudioCodeCredential: VisualStudioCodeCredential requires the 'azure-identity-broker' package to be installed. You must also ensure you have the Azure Resources extension installed and have signed in to Azure via Visual Studio Code.\n\tAzureCliCredential: Please run 'az login' to set up an account\n\tAzurePowerShellCredential: PowerShell is not installed\n\tAzureDeveloperCliCredential: Azure Developer CLI could not be found. Please visit https://aka.ms/azure-dev for installation instructions and then,once installed, authenticate to your Azure account using 'azd auth login'.\n\tBrokerCredential: InteractiveBrowserBrokerCredential unavailable. The 'azure-identity-broker' package is required to use brokered authentication.\nTo mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot."
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "cred = DefaultAzureCredential()\n",
    "token = cred.get_token(\"https://management.azure.com/.default\")\n",
    "print(\"Token acquired:\", token.token[:20], \"...\")  # prints first 20 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b9a7299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved agent: UKEF1\n",
      "Q: Explain coverage rules for UKEF projects.\n",
      "A: Simulated fallback: Coverage applies to low-risk projects up to £5M.\n",
      "--------------------------------------------------------------------------------\n",
      "Q: Summarize key points of my PhD methodology.\n",
      "A: PhD Agent simulated answer:\n",
      "Context:\n",
      "This is a sample PhD methodology document covering experiments and analysis.\n",
      "Question:\n",
      "Summarize key points of my PhD methodology.\n",
      "--------------------------------------------------------------------------------\n",
      "Q: How does the No Net Cost mandate apply?\n",
      "A: The 'No Net Cost' mandate requires UKEF to operate so that its long-term financial operations do not create a loss for HM Treasury. (Source: UKEF 'No Net Cost' mandate)\n",
      "--------------------------------------------------------------------------------\n",
      "Q: What is the maximum project risk we can cover?\n",
      "A: Not found in the documents.\n",
      "---\n",
      "PhD Agent simulated answer:\n",
      "Context:\n",
      "This is a sample PhD methodology document covering experiments and analysis.\n",
      "Question:\n",
      "What is the maximum project risk we can cover?\n",
      "---\n",
      "Finance Agent simulated answer:\n",
      "Context:\n",
      "Finance Agent docs: budgets, risk analysis, and cash flows.\n",
      "Question:\n",
      "What is the maximum project risk we can cover?\n",
      "--------------------------------------------------------------------------------\n",
      "Q: Provide budget insights for low-risk projects.\n",
      "A: Finance Agent simulated answer:\n",
      "Context:\n",
      "Finance Agent docs: budgets, risk analysis, and cash flows.\n",
      "Question:\n",
      "Provide budget insights for low-risk projects.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# =============================================\n",
    "# 2️⃣ Define UKEF Agent (Live Azure Option)\n",
    "# =============================================\n",
    "USE_AZURE_AGENT = True  # Set False to use simulated UKEF agent\n",
    "\n",
    "if USE_AZURE_AGENT:\n",
    "    myEndpoint = \"https://phd-agent-ukef-resource.services.ai.azure.com/api/projects/phd_agent_ukef\"\n",
    "    project_client = AIProjectClient(\n",
    "        endpoint=myEndpoint,\n",
    "        credential=DefaultAzureCredential(),\n",
    "    )\n",
    "    myAgent = \"UKEF1\"\n",
    "    agent = project_client.agents.get(agent_name=myAgent)\n",
    "    print(f\"Retrieved agent: {agent.name}\")\n",
    "    openai_client = project_client.get_openai_client()\n",
    "\n",
    "    def ask_ukef_agent(question):\n",
    "        try:\n",
    "            resp = openai_client.responses.create(\n",
    "                input=[{\"role\": \"user\", \"content\": question}],\n",
    "                extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "            )\n",
    "            answer = resp.output_text\n",
    "            if not answer.strip():\n",
    "                return \"Simulated fallback: Coverage applies to low-risk projects up to £5M.\"\n",
    "            return answer\n",
    "        except Exception:\n",
    "            return \"Simulated fallback: Coverage applies to low-risk projects up to £5M.\"\n",
    "else:\n",
    "    def ask_ukef_agent(question):\n",
    "        return \"Simulated fallback: Coverage applies to low-risk projects up to £5M.\"\n",
    "\n",
    "# =============================================\n",
    "# 3️⃣ Define PhD Agent (Simulated / Local RAG)\n",
    "# =============================================\n",
    "def ask_phd_agent(question):\n",
    "    folder = \"data_phd\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "        with open(f\"{folder}/doc1.txt\", \"w\") as f:\n",
    "            f.write(\"This is a sample PhD methodology document covering experiments and analysis.\")\n",
    "    \n",
    "    docs = [open(f\"{folder}/{f}\").read() for f in os.listdir(folder) if f.endswith(\".txt\")]\n",
    "    context = \"\\n\".join(docs)\n",
    "    return f\"PhD Agent simulated answer:\\nContext:\\n{context}\\nQuestion:\\n{question}\"\n",
    "\n",
    "# =============================================\n",
    "# 4️⃣ Define Finance Agent (Simulated)\n",
    "# =============================================\n",
    "def ask_finance_agent(question):\n",
    "    folder = \"data_finance\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "        with open(f\"{folder}/doc1.txt\", \"w\") as f:\n",
    "            f.write(\"Finance Agent docs: budgets, risk analysis, and cash flows.\")\n",
    "    \n",
    "    docs = [open(f\"{folder}/{f}\").read() for f in os.listdir(folder) if f.endswith(\".txt\")]\n",
    "    context = \"\\n\".join(docs)\n",
    "    return f\"Finance Agent simulated answer:\\nContext:\\n{context}\\nQuestion:\\n{question}\"\n",
    "\n",
    "# =============================================\n",
    "# 5️⃣ Orchestrator Agent\n",
    "# =============================================\n",
    "def orchestrator_agent(question):\n",
    "    \"\"\"\n",
    "    Orchestrator = agent itself\n",
    "    Routes queries to child agents and aggregates responses\n",
    "    \"\"\"\n",
    "    q = question.lower()\n",
    "    if \"ukef\" in q or \"coverage\" in q or \"mandate\" in q:\n",
    "        return ask_ukef_agent(question)\n",
    "    elif \"phd\" in q or \"research\" in q or \"methodology\" in q:\n",
    "        return ask_phd_agent(question)\n",
    "    elif \"finance\" in q or \"budget\" in q:\n",
    "        return ask_finance_agent(question)\n",
    "    else:\n",
    "        # Call all agents and aggregate\n",
    "        resp1 = ask_ukef_agent(question)\n",
    "        resp2 = ask_phd_agent(question)\n",
    "        resp3 = ask_finance_agent(question)\n",
    "        return f\"{resp1}\\n---\\n{resp2}\\n---\\n{resp3}\"\n",
    "\n",
    "# =============================================\n",
    "# 6️⃣ Example Queries / Demo\n",
    "# =============================================\n",
    "example_questions = [\n",
    "    \"Explain coverage rules for UKEF projects.\",\n",
    "    \"Summarize key points of my PhD methodology.\",\n",
    "    \"How does the No Net Cost mandate apply?\",\n",
    "    \"What is the maximum project risk we can cover?\",\n",
    "    \"Provide budget insights for low-risk projects.\"\n",
    "]\n",
    "\n",
    "for q in example_questions:\n",
    "    print(\"Q:\", q)\n",
    "    print(\"A:\", orchestrator_agent(q))\n",
    "    print(\"-\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2186c396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting semantic-kernel\n",
      "  Downloading semantic_kernel-1.39.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: azure-identity in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.26.0b1)\n",
      "Requirement already satisfied: openai in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.15.0)\n",
      "Collecting azure-ai-projects~=1.0.0b12 (from semantic-kernel)\n",
      "  Downloading azure_ai_projects-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting azure-ai-agents>=1.2.0b3 (from semantic-kernel)\n",
      "  Downloading azure_ai_agents-1.2.0b6-py3-none-any.whl.metadata (74 kB)\n",
      "Collecting aiohttp~=3.8 (from semantic-kernel)\n",
      "  Downloading aiohttp-3.13.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting cloudevents~=1.0 (from semantic-kernel)\n",
      "  Downloading cloudevents-1.12.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0 (from semantic-kernel)\n",
      "  Downloading pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting pydantic-settings~=2.0 (from semantic-kernel)\n",
      "  Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: defusedxml~=0.7 in /home/codespace/.local/lib/python3.12/site-packages (from semantic-kernel) (0.7.1)\n",
      "Collecting numpy>=1.26.0 (from semantic-kernel)\n",
      "  Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting openapi_core<0.20,>=0.18 (from semantic-kernel)\n",
      "  Downloading openapi_core-0.19.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting websockets<16,>=13 (from semantic-kernel)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting aiortc>=1.9.0 (from semantic-kernel)\n",
      "  Downloading aiortc-1.14.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting opentelemetry-api~=1.24 (from semantic-kernel)\n",
      "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-sdk~=1.24 (from semantic-kernel)\n",
      "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting prance<25.4.9,>=23.6.21 (from semantic-kernel)\n",
      "  Downloading prance-25.4.8.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pybars4~=0.9 (from semantic-kernel)\n",
      "  Downloading pybars4-0.9.13.tar.gz (29 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jinja2~=3.1 in /home/codespace/.local/lib/python3.12/site-packages (from semantic-kernel) (3.1.6)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in /home/codespace/.local/lib/python3.12/site-packages (from semantic-kernel) (1.6.0)\n",
      "Collecting scipy>=1.15.1 (from semantic-kernel)\n",
      "  Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting protobuf (from semantic-kernel)\n",
      "  Downloading protobuf-6.33.4-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: typing-extensions>=4.13 in /home/codespace/.local/lib/python3.12/site-packages (from semantic-kernel) (4.15.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp~=3.8->semantic-kernel) (25.4.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-ai-projects~=1.0.0b12->semantic-kernel) (0.7.2)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-ai-projects~=1.0.0b12->semantic-kernel) (1.38.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.15.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-ai-projects~=1.0.0b12->semantic-kernel) (12.28.0)\n",
      "Collecting deprecation<3.0,>=2.0 (from cloudevents~=1.0->semantic-kernel)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from deprecation<3.0,>=2.0->cloudevents~=1.0->semantic-kernel) (25.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2~=3.1->semantic-kernel) (3.0.3)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /home/codespace/.local/lib/python3.12/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.25.1)\n",
      "Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting more-itertools (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading openapi_schema_validator-0.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading openapi_spec_validator-0.7.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting parse (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting werkzeug<3.1.2 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading werkzeug-3.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.29.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (6.0.3)\n",
      "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (2.32.5)\n",
      "Requirement already satisfied: rfc3339-validator in /home/codespace/.local/lib/python3.12/site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.1.4)\n",
      "Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api~=1.24->semantic-kernel)\n",
      "  Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk~=1.24->semantic-kernel)\n",
      "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting chardet>=5.2 (from prance<25.4.9,>=23.6.21->semantic-kernel)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting ruamel.yaml>=0.18.10 (from prance<25.4.9,>=23.6.21->semantic-kernel)\n",
      "  Downloading ruamel_yaml-0.19.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting PyMeta3>=0.5.1 (from pybars4~=0.9->semantic-kernel)\n",
      "  Downloading PyMeta3-0.5.1.tar.gz (29 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.7.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.4.2)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings~=2.0->semantic-kernel)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (2.5.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-identity) (46.0.3)\n",
      "Requirement already satisfied: msal>=1.30.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-identity) (1.35.0b1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-identity) (1.3.1)\n",
      "Collecting aioice<1.0.0,>=0.10.1 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading aioice-0.10.2-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting av<17.0.0,>=14.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading av-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting google-crc32c>=1.1 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading google_crc32c-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting pyee>=13.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pylibsrtp>=0.10.0 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading pylibsrtp-1.0.0-cp310-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting pyopenssl>=25.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading pyopenssl-25.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting dnspython>=2.0.0 (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting ifaddr>=0.2.0 (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading ifaddr-0.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity) (2.23)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity) (2.10.1)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.12/site-packages (from rfc3339-validator->openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel) (1.17.0)\n",
      "Downloading semantic_kernel-1.39.2-py3-none-any.whl (910 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m910.9/910.9 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.13.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_ai_projects-1.0.0-py3-none-any.whl (115 kB)\n",
      "Downloading cloudevents-1.12.0-py3-none-any.whl (55 kB)\n",
      "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Downloading openapi_core-0.19.5-py3-none-any.whl (106 kB)\n",
      "Downloading jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n",
      "Downloading openapi_schema_validator-0.6.3-py3-none-any.whl (8.8 kB)\n",
      "Downloading openapi_spec_validator-0.7.2-py3-none-any.whl (39 kB)\n",
      "Downloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "Downloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
      "Downloading importlib_metadata-8.7.1-py3-none-any.whl (27 kB)\n",
      "Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
      "Downloading pathable-0.4.4-py3-none-any.whl (9.6 kB)\n",
      "Downloading prance-25.4.8.0-py3-none-any.whl (36 kB)\n",
      "Downloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Downloading werkzeug-3.1.1-py3-none-any.whl (224 kB)\n",
      "Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiortc-1.14.0-py3-none-any.whl (93 kB)\n",
      "Downloading aioice-0.10.2-py3-none-any.whl (24 kB)\n",
      "Downloading av-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading azure_ai_agents-1.2.0b6-py3-none-any.whl (217 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
      "Downloading google_crc32c-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (33 kB)\n",
      "Downloading ifaddr-0.2.0-py3-none-any.whl (12 kB)\n",
      "Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
      "Downloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
      "Downloading pylibsrtp-1.0.0-cp310-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyopenssl-25.3.0-py3-none-any.whl (57 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading ruamel_yaml-0.19.1-py3-none-any.whl (118 kB)\n",
      "Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (35.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
      "Downloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
      "Downloading protobuf-6.33.4-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Building wheels for collected packages: pybars4, PyMeta3\n",
      "  Building wheel for pybars4 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pybars4: filename=pybars4-0.9.13-py3-none-any.whl size=14418 sha256=452ff0cf071335a73e16f23ad963645d75cf28911d67d9d74a55c3e357aeb765\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/75/2d/da/c75b2fc7b00dc9c154dff65f689a318e7d24b44c612c2b21f1\n",
      "  Building wheel for PyMeta3 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyMeta3: filename=pymeta3-0.5.1-py3-none-any.whl size=16519 sha256=b7d39abb314e6d26385beca37abba8b9d0bd7065755306a5517cab174d1c27ac\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/5a/9b/2c/81b7551d2c05a482817e6c3b3d2f8ad2a0229db874c4bc6346\n",
      "Successfully built pybars4 PyMeta3\n",
      "Installing collected packages: PyMeta3, parse, ifaddr, zipp, werkzeug, websockets, ruamel.yaml, referencing, python-dotenv, pyee, pydantic-core, pybars4, protobuf, propcache, pathable, numpy, multidict, more-itertools, lazy-object-proxy, google-crc32c, frozenlist, dnspython, deprecation, chardet, av, aiohappyeyeballs, yarl, scipy, pylibsrtp, pydantic, prance, jsonschema-path, importlib-metadata, cloudevents, aiosignal, aioice, pyopenssl, pydantic-settings, opentelemetry-api, openai, azure-ai-agents, aiohttp, opentelemetry-semantic-conventions, openapi-schema-validator, azure-ai-projects, aiortc, opentelemetry-sdk, openapi-spec-validator, openapi_core, semantic-kernel\n",
      "\u001b[2K  Attempting uninstall: referencing━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/50\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K    Found existing installation: referencing 0.37.0━━━━━━━━━━━\u001b[0m \u001b[32m 6/50\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K    Uninstalling referencing-0.37.0:━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/50\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K      Successfully uninstalled referencing-0.37.0━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/50\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K  Attempting uninstall: pydantic-core━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/50\u001b[0m [referencing]\n",
      "\u001b[2K    Found existing installation: pydantic_core 2.41.5━━━━━━━━━\u001b[0m \u001b[32m 7/50\u001b[0m [referencing]\n",
      "\u001b[2K    Uninstalling pydantic_core-2.41.5:━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/50\u001b[0m [referencing]\n",
      "\u001b[2K      Successfully uninstalled pydantic_core-2.41.5━━━━━━━━━━━\u001b[0m \u001b[32m 7/50\u001b[0m [referencing]\n",
      "\u001b[2K  Attempting uninstall: pydanticm\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/50\u001b[0m [scipy]t]n]\n",
      "\u001b[2K    Found existing installation: pydantic 2.12.5━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/50\u001b[0m [scipy]\n",
      "\u001b[2K    Uninstalling pydantic-2.12.5:m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/50\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.12.5━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/50\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: openai━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m37/50\u001b[0m [pydantic-settings]\n",
      "\u001b[2K    Found existing installation: openai 2.15.0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m37/50\u001b[0m [pydantic-settings]\n",
      "\u001b[2K    Uninstalling openai-2.15.0:━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m39/50\u001b[0m [openai]ttings]\n",
      "\u001b[2K      Successfully uninstalled openai-2.15.0╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m39/50\u001b[0m [openai]\n",
      "\u001b[2K  Attempting uninstall: azure-ai-projects[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m42/50\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K    Found existing installation: azure-ai-projects 2.0.0b30m \u001b[32m42/50\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K    Uninstalling azure-ai-projects-2.0.0b3:[0m\u001b[90m━━━━━\u001b[0m \u001b[32m42/50\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K      Successfully uninstalled azure-ai-projects-2.0.0b3\u001b[0m \u001b[32m42/50\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/50\u001b[0m [semantic-kernel]c-kernel]_core]validator]s]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PyMeta3-0.5.1 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aioice-0.10.2 aiortc-1.14.0 aiosignal-1.4.0 av-16.1.0 azure-ai-agents-1.2.0b6 azure-ai-projects-1.0.0 chardet-5.2.0 cloudevents-1.12.0 deprecation-2.1.0 dnspython-2.8.0 frozenlist-1.8.0 google-crc32c-1.8.0 ifaddr-0.2.0 importlib-metadata-8.7.1 jsonschema-path-0.3.4 lazy-object-proxy-1.12.0 more-itertools-10.8.0 multidict-6.7.0 numpy-2.4.1 openai-1.109.1 openapi-schema-validator-0.6.3 openapi-spec-validator-0.7.2 openapi_core-0.19.5 opentelemetry-api-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 parse-1.20.2 pathable-0.4.4 prance-25.4.8.0 propcache-0.4.1 protobuf-6.33.4 pybars4-0.9.13 pydantic-2.11.10 pydantic-core-2.33.2 pydantic-settings-2.12.0 pyee-13.0.0 pylibsrtp-1.0.0 pyopenssl-25.3.0 python-dotenv-1.2.1 referencing-0.36.2 ruamel.yaml-0.19.1 scipy-1.17.0 semantic-kernel-1.39.2 websockets-15.0.1 werkzeug-3.1.1 yarl-1.22.0 zipp-3.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install semantic-kernel azure-identity openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2296bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install semantic-kernel azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f57107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "kernel = sk.Kernel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "581f2688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPlugin(name='PhD', description=None, functions={'PhDAgent': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='PhDAgent', plugin_name='PhD', description='Handles academic methodology, research experiments, and thesis evaluation.', parameters=[KernelParameterMetadata(name='query', description=None, default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True)], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x77f5ddf5dd60>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x77f5de781a60>, method=<bound method PhDPlugin.get_research of <__main__.PhDPlugin object at 0x77f5de7810a0>>, stream_method=None)})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Define Native Plugins ---\n",
    "\n",
    "class UKEFPlugin:\n",
    "    @kernel_function(\n",
    "        name=\"UKEFAgent\",\n",
    "        description=\"Provides policy coverage details and financial limits for UKEF projects.\"\n",
    "    )\n",
    "    def get_coverage(self, query: str) -> str:\n",
    "        # This is where your CSV-reading logic would live\n",
    "        return \"UKEF policy coverage applies to low-risk projects up to £5M.\"\n",
    "\n",
    "class PhDPlugin:\n",
    "    @kernel_function(\n",
    "        name=\"PhDAgent\",\n",
    "        description=\"Handles academic methodology, research experiments, and thesis evaluation.\"\n",
    "    )\n",
    "    def get_research(self, query: str) -> str:\n",
    "        return \"PhD agent: Specialized in methodology and systematic evaluation.\"\n",
    "\n",
    "# --- Register Plugins ---\n",
    "kernel.add_plugin(UKEFPlugin(), plugin_name=\"UKEF\")\n",
    "kernel.add_plugin(PhDPlugin(), plugin_name=\"PhD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44920f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings\n",
    "\n",
    "async def agentic_orchestrator(query: str):\n",
    "    # Set behavior to automatically call functions (plugins)\n",
    "    settings = AzureChatPromptExecutionSettings(\n",
    "        function_choice_behavior=FunctionChoiceBehavior.Auto()\n",
    "    )\n",
    "    \n",
    "    # We use invoke_prompt. The LLM sees the description of UKEFAgent and PhDAgent\n",
    "    # and decides which one to call based on the user's intent.\n",
    "    result = await kernel.invoke_prompt(\n",
    "        function_name=\"Orchestrator\",\n",
    "        plugin_name=\"Main\",\n",
    "        prompt=query,\n",
    "        settings=settings\n",
    "    )\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f49bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: The 'Clean Slate' approach (Recommended for Notebooks)\n",
    "#kernel.remove_all_services()\n",
    "\n",
    "# Now add your fixed service with the token_provider\n",
    "#kernel.add_service(azure_chat)\n",
    "\n",
    "# Option 2: The 'Overwrite' approach\n",
    "# kernel.add_service(azure_chat, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8ce561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# 1. Create the credential\n",
    "cred = DefaultAzureCredential()\n",
    "\n",
    "# 2. CREATE A TOKEN PROVIDER with the correct 'Cognitive Services' scope\n",
    "# This is the \"Magic Sauce\" that fixes the 401 Audience error\n",
    "token_provider = get_bearer_token_provider(\n",
    "    cred, \n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "\n",
    "# 3. Initialize AzureChatCompletion using the token_provider\n",
    "azure_chat = AzureChatCompletion(\n",
    "    deployment_name=\"gpt-4o\",\n",
    "    endpoint=myEndpoint,\n",
    "    ad_token_provider=token_provider # Use this instead of passing 'cred' directly\n",
    ")\n",
    "\n",
    "kernel.add_service(azure_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bca08e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Kernel initialized from scratch. No conflicts!\n"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "\n",
    "# 1. Complete Kernel Reset\n",
    "kernel = sk.Kernel() \n",
    "\n",
    "# 2. Add the service with the fixed token provider\n",
    "# (Make sure azure_chat is already defined with ad_token_provider)\n",
    "kernel.add_service(azure_chat)\n",
    "\n",
    "# 3. Re-register Plugins (This overwrites anything old)\n",
    "# We don't need to \"remove\" them because we made a 'new' kernel above\n",
    "kernel.add_plugin(UKEFPlugin(), plugin_name=\"UKEF\")\n",
    "kernel.add_plugin(PhDPlugin(), plugin_name=\"PhD\")\n",
    "\n",
    "print(\"✅ Kernel initialized from scratch. No conflicts!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66b853b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "# 1. Create the credential as before\n",
    "cred = DefaultAzureCredential()\n",
    "\n",
    "# 2. CREATE A TOKEN PROVIDER with the specific scope for AI services\n",
    "# This specifically fixes the \"audience is incorrect\" error.\n",
    "token_provider = get_bearer_token_provider(\n",
    "    cred, \n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "\n",
    "# 3. Update your AzureChatCompletion to use 'ad_token_provider'\n",
    "azure_chat = AzureChatCompletion(\n",
    "    deployment_name=\"gpt-4o\",\n",
    "    endpoint=myEndpoint,\n",
    "    ad_token_provider=token_provider  # Use the provider, not the raw credential\n",
    ")\n",
    "\n",
    "# 4. Clean and re-add the service to avoid the \"Already Exists\" error\n",
    "kernel.remove_all_services()\n",
    "kernel.add_service(azure_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "610f01b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING MULTI-AGENT TEST ---\n",
      "\n",
      "USER QUERY: What is the maximum coverage for a UKEF project?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function failed. Error: Error occurred while invoking function ovjXKAirgUDJaWtU: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", APIConnectionError('Connection error.'))\n",
      "Something went wrong in function invocation. During function invocation: 'ovjXKAirgUDJaWtU'. Error description: 'Error occurred while invoking function ovjXKAirgUDJaWtU: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", APIConnectionError('Connection error.'))'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ TEST ERROR: Error occurred while invoking function: 'ovjXKAirgUDJaWtU'\n",
      "\n",
      "USER QUERY: Can you explain the methodology for my PhD research?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function failed. Error: Error occurred while invoking function tXGSwsZapDIGUosw: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", APIConnectionError('Connection error.'))\n",
      "Something went wrong in function invocation. During function invocation: 'tXGSwsZapDIGUosw'. Error description: 'Error occurred while invoking function tXGSwsZapDIGUosw: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", APIConnectionError('Connection error.'))'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ TEST ERROR: Error occurred while invoking function: 'tXGSwsZapDIGUosw'\n",
      "\n",
      "USER QUERY: Give me a summary of UKEF rules and academic research steps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function failed. Error: Error occurred while invoking function xMDZHrroLpiHgOym: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", APIConnectionError('Connection error.'))\n",
      "Something went wrong in function invocation. During function invocation: 'xMDZHrroLpiHgOym'. Error description: 'Error occurred while invoking function xMDZHrroLpiHgOym: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", APIConnectionError('Connection error.'))'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ TEST ERROR: Error occurred while invoking function: 'xMDZHrroLpiHgOym'\n",
      "\n",
      "--- TEST COMPLETE ---\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import semantic_kernel as sk\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "# --- STEP 1: DEFINE YOUR AGENT PLUGINS ---\n",
    "class UKEFPlugin:\n",
    "    @kernel_function(description=\"Explains UKEF project coverage and financial rules.\")\n",
    "    def get_coverage(self, query: str) -> str:\n",
    "        return \"UKEF coverage applies to low-risk projects up to £5M. (Source: UKEF Manual)\"\n",
    "\n",
    "class PhDPlugin:\n",
    "    @kernel_function(description=\"Handles academic methodology and PhD research steps.\")\n",
    "    def get_research(self, query: str) -> str:\n",
    "        return \"PhD Methodology includes experimental design and data analysis. (Source: PhD Draft)\"\n",
    "\n",
    "async def run_complete_demo():\n",
    "    # --- STEP 2: SETUP IDENTITY & KERNEL ---\n",
    "    # This specific scope fix removes the 401 \"Audience Incorrect\" error\n",
    "    token_provider = get_bearer_token_provider(\n",
    "        DefaultAzureCredential(), \n",
    "        \"https://cognitiveservices.azure.com/.default\"\n",
    "    )\n",
    "\n",
    "    # Initialize a CLEAN kernel (no duplicate service errors)\n",
    "    kernel = sk.Kernel()\n",
    "\n",
    "    # Add the \"Brain\" (GPT-4o)\n",
    "    azure_chat = AzureChatCompletion(\n",
    "        deployment_name=\"gpt-4o\",  # Your deployment name\n",
    "        endpoint=\"https://YOUR-RESOURCE.openai.azure.com/\", # Replace with your actual endpoint\n",
    "        ad_token_provider=token_provider\n",
    "    )\n",
    "    kernel.add_service(azure_chat)\n",
    "\n",
    "    # Register the Agents\n",
    "    kernel.add_plugin(UKEFPlugin(), plugin_name=\"UKEF\")\n",
    "    kernel.add_plugin(PhDPlugin(), plugin_name=\"PhD\")\n",
    "\n",
    "    # --- STEP 3: THE TEST LOOP ---\n",
    "    test_queries = [\n",
    "        \"What is the maximum coverage for a UKEF project?\",\n",
    "        \"Can you explain the methodology for my PhD research?\",\n",
    "        \"Give me a summary of UKEF rules and academic research steps.\"\n",
    "    ]\n",
    "\n",
    "    print(\"--- STARTING MULTI-AGENT TEST ---\")\n",
    "    for query in test_queries:\n",
    "        print(f\"\\nUSER QUERY: {query}\")\n",
    "        try:\n",
    "            # We use the kernel to invoke the query directly\n",
    "            # The 'Auto' setting tells GPT-4o to choose the right plugin\n",
    "            result = await kernel.invoke_prompt(\n",
    "                query,\n",
    "                # This bit tells the kernel to automatically call the plugins\n",
    "                settings=sk.connectors.ai.open_ai.AzureChatPromptExecutionSettings(\n",
    "                    function_choice_behavior=\"auto\"\n",
    "                )\n",
    "            )\n",
    "            print(f\"AGENT RESPONSE: {result}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ TEST ERROR: {e}\")\n",
    "    \n",
    "    print(\"\\n--- TEST COMPLETE ---\")\n",
    "\n",
    "# Run everything\n",
    "await run_complete_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65eb0e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ System fully reset with cleaned endpoint and stable API version.\n"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "# --- 1. CLEAN YOUR ENDPOINT ---\n",
    "# Ensure myEndpoint is ONLY: https://your-resource-name.openai.azure.com/\n",
    "# (No trailing slashes, no /openai/ path)\n",
    "clean_endpoint = myEndpoint.split(\"/openai/\")[0].strip(\"/\")\n",
    "\n",
    "# --- 2. SETUP IDENTITY ---\n",
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(), \n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "\n",
    "# --- 3. INITIALIZE SERVICE WITH STABLE API VERSION ---\n",
    "azure_chat = AzureChatCompletion(\n",
    "    deployment_name=\"gpt-4o\",\n",
    "    endpoint=clean_endpoint,\n",
    "    ad_token_provider=token_provider,\n",
    "    api_version=\"2024-05-01-preview\" # Using a guaranteed stable version\n",
    ")\n",
    "\n",
    "# --- 4. CLEAN RESET ---\n",
    "kernel = sk.Kernel()\n",
    "kernel.add_service(azure_chat)\n",
    "\n",
    "# --- 5. RE-REGISTER PLUGINS ---\n",
    "# Ensure these classes are defined in your notebook!\n",
    "kernel.add_plugin(UKEFPlugin(), plugin_name=\"UKEF\")\n",
    "kernel.add_plugin(PhDPlugin(), plugin_name=\"PhD\")\n",
    "\n",
    "print(\"✅ System fully reset with cleaned endpoint and stable API version.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc98c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# Test if your environment can even \"see\" the endpoint\n",
    "try:\n",
    "    response = requests.get(clean_endpoint)\n",
    "    print(f\"Network Check: Connection successful (Status: {response.status_code})\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Network Check Failed: Your firewall or VPN is blocking the connection. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ae795f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scope MUST be cognitiveservices, not ai.azure.com\n",
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(), \n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6f86365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Launching Group Chat with Manual Token Authorization...\n"
     ]
    },
    {
     "ename": "ServiceResponseException",
     "evalue": "(\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", AuthenticationError(\"Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://ai.azure.com), or have expired.'}\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:88\u001b[39m, in \u001b[36mOpenAIHandler._send_completion_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m     87\u001b[39m         settings_dict.pop(\u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.chat.completions.create(**settings_dict)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:2678\u001b[39m, in \u001b[36mcreate\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2663\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get(\n\u001b[32m   2664\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/chat/completions/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompletion_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   2665\u001b[39m         options=make_request_options(\n\u001b[32m   (...)\u001b[39m\u001b[32m   2668\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m   2669\u001b[39m     )\n\u001b[32m   2671\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate\u001b[39m(\n\u001b[32m   2672\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2673\u001b[39m     completion_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   2674\u001b[39m     *,\n\u001b[32m   2675\u001b[39m     metadata: Optional[Metadata],\n\u001b[32m   2676\u001b[39m     \u001b[38;5;66;03m# Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.\u001b[39;00m\n\u001b[32m   2677\u001b[39m     \u001b[38;5;66;03m# The extra values given here take precedence over values defined on the client or passed to this method.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2678\u001b[39m     extra_headers: Headers | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2679\u001b[39m     extra_query: Query | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2680\u001b[39m     extra_body: Body | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2681\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   2682\u001b[39m ) -> ChatCompletion:\n\u001b[32m   2683\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Modify a stored chat completion.\u001b[39;00m\n\u001b[32m   2684\u001b[39m \n\u001b[32m   2685\u001b[39m \u001b[33;03m    Only Chat Completions that have been created\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2703\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m   2704\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/_base_client.py:1797\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1794\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n\u001b[32m   1796\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpatch\u001b[39m(\n\u001b[32m-> \u001b[39m\u001b[32m1797\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1798\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   1799\u001b[39m     *,\n\u001b[32m   1800\u001b[39m     cast_to: Type[ResponseT],\n\u001b[32m   1801\u001b[39m     body: Body | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1802\u001b[39m     options: RequestOptions = {},\n\u001b[32m   1803\u001b[39m ) -> ResponseT:\n\u001b[32m   1804\u001b[39m     opts = FinalRequestOptions.construct(method=\u001b[33m\"\u001b[39m\u001b[33mpatch\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/_base_client.py:1597\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://ai.azure.com), or have expired.'}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mServiceResponseException\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m30\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Run it\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m start_final_chat()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mstart_final_chat\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m chat.add_chat_message(query)\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m🚀 Launching Group Chat with Manual Token Authorization...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m content \u001b[38;5;129;01min\u001b[39;00m chat.invoke():\n\u001b[32m     42\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m30\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/agents/group_chat/agent_group_chat.py:156\u001b[39m, in \u001b[36mAgentGroupChat.invoke\u001b[39m\u001b[34m(self, agent, is_joining)\u001b[39m\n\u001b[32m    153\u001b[39m     logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to select agent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AgentChatException(\u001b[33m\"\u001b[39m\u001b[33mFailed to select agent\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().invoke_agent(selected_agent):\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m message.role == AuthorRole.ASSISTANT:\n\u001b[32m    158\u001b[39m         task = \u001b[38;5;28mself\u001b[39m.termination_strategy.should_terminate(selected_agent, \u001b[38;5;28mself\u001b[39m.history.messages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/agents/group_chat/agent_chat.py:149\u001b[39m, in \u001b[36mAgentChat.invoke_agent\u001b[39m\u001b[34m(self, agent)\u001b[39m\n\u001b[32m    146\u001b[39m channel: AgentChannel = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_or_create_channel(agent)\n\u001b[32m    147\u001b[39m messages: \u001b[38;5;28mlist\u001b[39m[ChatMessageContent] = []\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m is_visible, message \u001b[38;5;129;01min\u001b[39;00m channel.invoke(agent):\n\u001b[32m    150\u001b[39m     messages.append(message)\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.history.messages.append(message)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/agents/channels/chat_history_channel.py:65\u001b[39m, in \u001b[36mChatHistoryChannel.invoke\u001b[39m\u001b[34m(self, agent, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m mutated_history = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m     63\u001b[39m message_queue: Deque[ChatMessageContent] = deque()\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m agent.invoke(\n\u001b[32m     66\u001b[39m     messages=\u001b[38;5;28mself\u001b[39m.messages[-\u001b[32m1\u001b[39m],\n\u001b[32m     67\u001b[39m     thread=\u001b[38;5;28mself\u001b[39m.thread,\n\u001b[32m     68\u001b[39m ):\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# Capture all messages that have been included in the mutated history.\u001b[39;00m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m message_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(message_count, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.messages)):\n\u001b[32m     71\u001b[39m         mutated_message = \u001b[38;5;28mself\u001b[39m.messages[message_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/utils/telemetry/agent_diagnostics/decorators.py:106\u001b[39m, in \u001b[36mtrace_agent_invocation.<locals>.wrapper_decorator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(invoke_func)\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_decorator\u001b[39m(\n\u001b[32m    101\u001b[39m     *args: P.args,\n\u001b[32m    102\u001b[39m     **kwargs: P.kwargs,\n\u001b[32m    103\u001b[39m ) -> AsyncIterable[AgentResponseItem[ChatMessageContent]]:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n\u001b[32m    105\u001b[39m         \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the responses\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m invoke_func(*args, **kwargs):\n\u001b[32m    107\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m response\n\u001b[32m    108\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/agents/chat_completion/chat_completion_agent.py:364\u001b[39m, in \u001b[36mChatCompletionAgent.invoke\u001b[39m\u001b[34m(self, messages, thread, on_intermediate_message, arguments, kernel, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m thread.get_messages():\n\u001b[32m    362\u001b[39m     chat_history.add_message(message)\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_invoke(\n\u001b[32m    365\u001b[39m     thread,\n\u001b[32m    366\u001b[39m     chat_history,\n\u001b[32m    367\u001b[39m     on_intermediate_message,\n\u001b[32m    368\u001b[39m     arguments,\n\u001b[32m    369\u001b[39m     kernel,\n\u001b[32m    370\u001b[39m     **kwargs,\n\u001b[32m    371\u001b[39m ):\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m AgentResponseItem(message=response, thread=thread)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/agents/chat_completion/chat_completion_agent.py:537\u001b[39m, in \u001b[36mChatCompletionAgent._inner_invoke\u001b[39m\u001b[34m(self, thread, history, on_intermediate_message, arguments, kernel, **kwargs)\u001b[39m\n\u001b[32m    533\u001b[39m message_count_before_completion = \u001b[38;5;28mlen\u001b[39m(agent_chat_history)\n\u001b[32m    535\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Invoking \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(chat_completion_service).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m responses = \u001b[38;5;28;01mawait\u001b[39;00m chat_completion_service.get_chat_message_contents(\n\u001b[32m    538\u001b[39m     chat_history=agent_chat_history,\n\u001b[32m    539\u001b[39m     settings=settings,\n\u001b[32m    540\u001b[39m     kernel=kernel,\n\u001b[32m    541\u001b[39m     arguments=arguments,\n\u001b[32m    542\u001b[39m )\n\u001b[32m    544\u001b[39m logger.debug(\n\u001b[32m    545\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Invoked \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(chat_completion_service).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    546\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwith message count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage_count_before_completion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    547\u001b[39m )\n\u001b[32m    549\u001b[39m \u001b[38;5;66;03m# Drain newly added tool messages since last index to maintain\u001b[39;00m\n\u001b[32m    550\u001b[39m \u001b[38;5;66;03m# correct order and avoid duplicates\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/chat_completion_client_base.py:139\u001b[39m, in \u001b[36mChatCompletionClientBase.get_chat_message_contents\u001b[39m\u001b[34m(self, chat_history, settings, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m use_span(\u001b[38;5;28mself\u001b[39m._start_auto_function_invocation_activity(kernel, settings), end_on_exit=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m _:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m request_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(settings.function_choice_behavior.maximum_auto_invoke_attempts):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m         completions = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_get_chat_message_contents(chat_history, settings)\n\u001b[32m    140\u001b[39m         \u001b[38;5;66;03m# Get the function call contents from the chat message. There is only one chat message,\u001b[39;00m\n\u001b[32m    141\u001b[39m         \u001b[38;5;66;03m# which should be checked in the `_verify_function_choice_settings` method.\u001b[39;00m\n\u001b[32m    142\u001b[39m         function_calls = [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m completions[\u001b[32m0\u001b[39m].items \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, FunctionCallContent)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/utils/telemetry/model_diagnostics/decorators.py:110\u001b[39m, in \u001b[36mtrace_chat_completion.<locals>.inner_trace_chat_completion.<locals>.wrapper_decorator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(completion_func)\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_decorator\u001b[39m(*args: Any, **kwargs: Any) -> \u001b[38;5;28mlist\u001b[39m[ChatMessageContent]:\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n\u001b[32m    109\u001b[39m         \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m completion_func(*args, **kwargs)\n\u001b[32m    112\u001b[39m     completion_service: \u001b[33m\"\u001b[39m\u001b[33mChatCompletionClientBase\u001b[39m\u001b[33m\"\u001b[39m = args[\u001b[32m0\u001b[39m]\n\u001b[32m    113\u001b[39m     chat_history: ChatHistory = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mchat_history\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_chat_completion_base.py:88\u001b[39m, in \u001b[36mOpenAIChatCompletionBase._inner_get_chat_message_contents\u001b[39m\u001b[34m(self, chat_history, settings)\u001b[39m\n\u001b[32m     85\u001b[39m settings.messages = \u001b[38;5;28mself\u001b[39m._prepare_chat_history_for_request(chat_history)\n\u001b[32m     86\u001b[39m settings.ai_model_id = settings.ai_model_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_id\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_request(settings)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, ChatCompletion)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[32m     90\u001b[39m response_metadata = \u001b[38;5;28mself\u001b[39m._get_metadata_from_chat_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:60\u001b[39m, in \u001b[36mOpenAIHandler._send_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.TEXT \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.CHAT:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_completion_request(settings)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.EMBEDDING:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIEmbeddingPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:105\u001b[39m, in \u001b[36mOpenAIHandler._send_completion_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[32m    101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service failed to complete the prompt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    102\u001b[39m         ex,\n\u001b[32m    103\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[32m    106\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service failed to complete the prompt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    107\u001b[39m         ex,\n\u001b[32m    108\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n",
      "\u001b[31mServiceResponseException\u001b[39m: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", AuthenticationError(\"Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://ai.azure.com), or have expired.'}\"))"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.agents import AgentGroupChat, ChatCompletionAgent\n",
    "\n",
    "# --- 1. FORCE THE CORRECT TOKEN SCOPE ---\n",
    "# We bypass the 'provider' and get the raw token for the Data Plane\n",
    "cred = DefaultAzureCredential()\n",
    "token_info = cred.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "manual_token = token_info.token\n",
    "\n",
    "# --- 2. INITIALIZE KERNEL WITH THE RAW TOKEN ---\n",
    "kernel = sk.Kernel()\n",
    "kernel.add_service(AzureChatCompletion(\n",
    "    deployment_name=\"gpt-4o\",\n",
    "    endpoint=clean_endpoint,\n",
    "    api_key=manual_token, # We pass the token directly as the key\n",
    "))\n",
    "\n",
    "# --- 3. SETUP THE AGENTS ---\n",
    "agent_ukef = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"UKEF_Expert\",\n",
    "    instructions=\"You are a UKEF specialist. Explain the 'No Net Cost' mandate.\"\n",
    ")\n",
    "\n",
    "agent_phd = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"PhD_Supervisor\",\n",
    "    instructions=\"You are a PhD supervisor. Integrate financial rules into research.\"\n",
    ")\n",
    "\n",
    "# --- 4. EXECUTE THE CHAT ---\n",
    "async def start_final_chat():\n",
    "    chat = AgentGroupChat(agents=[agent_ukef, agent_phd])\n",
    "    query = \"How can I include UKEF's 'No Net Cost' mandate into the financial methodology of my PhD?\"\n",
    "    \n",
    "    await chat.add_chat_message(query)\n",
    "    print(f\"🚀 Launching Group Chat with Manual Token Authorization...\")\n",
    "    \n",
    "    async for content in chat.invoke():\n",
    "        print(f\"\\n[{content.name}]: {content.content}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "# Run it\n",
    "await start_final_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1550f20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function failed. Error: Argument 'template_params' has a value that doesn't support automatic encoding. Set allow_dangerously_set_content to 'True' for this argument and implement custom encoding, or provide the value as a string.\n",
      "Something went wrong in function invocation. During function invocation: 'Orchestrator-CombinedExpert'. Error description: 'Argument 'template_params' has a value that doesn't support automatic encoding. Set allow_dangerously_set_content to 'True' for this argument and implement custom encoding, or provide the value as a string.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Running Direct Kernel Test (Bypassing Agent SDK)...\n",
      "❌ KERNEL ERROR: Error occurred while invoking function: 'Orchestrator-CombinedExpert'\n"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "# 1. THE RECOVERY\n",
    "cred = DefaultAzureCredential()\n",
    "# Explicitly grab the token for the model data plane\n",
    "token_info = cred.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "# 2. THE STABLE KERNEL\n",
    "# We use 'ad_token' directly in the connector - this is the most stable path\n",
    "kernel = sk.Kernel()\n",
    "kernel.add_service(AzureChatCompletion(\n",
    "    deployment_name=\"gpt-4o\",\n",
    "    endpoint=clean_endpoint,\n",
    "    api_key=token_info.token # Force the token here\n",
    "))\n",
    "\n",
    "# 3. THE \"DIRECT\" CHAT TEST (No AgentGroupChat wrappers)\n",
    "async def quick_chat():\n",
    "    print(\"🚀 Running Direct Kernel Test (Bypassing Agent SDK)...\")\n",
    "    \n",
    "    # Combined prompt to act as both experts\n",
    "    prompt = \"\"\"\n",
    "    You are a system containing two experts: a UKEF Specialist and a PhD Supervisor.\n",
    "    User Question: {input}\n",
    "    \n",
    "    Provide a combined response addressing both the financial mandate and the academic methodology.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_query = \"How can I include UKEF's 'No Net Cost' mandate into the financial methodology of my PhD?\"\n",
    "    \n",
    "    try:\n",
    "        # Call the kernel directly\n",
    "        result = await kernel.invoke_prompt(\n",
    "            function_name=\"CombinedExpert\",\n",
    "            plugin_name=\"Orchestrator\",\n",
    "            prompt=prompt,\n",
    "            template_params={\"input\": user_query}\n",
    "        )\n",
    "        print(f\"\\nFINAL ANSWER:\\n{result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ KERNEL ERROR: {e}\")\n",
    "\n",
    "# Execute\n",
    "await quick_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "18cb3c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function failed. Error: Error occurred while invoking function AYjohFuelbyWDXbd: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", AuthenticationError(\"Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://ai.azure.com), or have expired.'}\"))\n",
      "Something went wrong in function invocation. During function invocation: 'AYjohFuelbyWDXbd'. Error description: 'Error occurred while invoking function AYjohFuelbyWDXbd: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", AuthenticationError(\"Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://ai.azure.com), or have expired.'}\"))'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Running Direct Kernel Test (V1.0 Fixed Arguments)...\n",
      "❌ KERNEL ERROR: Error occurred while invoking function: 'AYjohFuelbyWDXbd'\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "async def quick_chat_v2():\n",
    "    print(\"🚀 Running Direct Kernel Test (V1.0 Fixed Arguments)...\")\n",
    "    \n",
    "    # We define the prompt with the V1.0 variable syntax: {{$input}}\n",
    "    prompt_template = \"\"\"\n",
    "    You are a system containing two experts: a UKEF Specialist and a PhD Supervisor.\n",
    "    User Question: {{$input}}\n",
    "    \n",
    "    Provide a combined response addressing both the financial mandate and the academic methodology.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We use KernelArguments to safely pass the data\n",
    "    # This avoids the \"automatic encoding\" error entirely\n",
    "    args = KernelArguments(input=\"How can I include UKEF's 'No Net Cost' mandate into the financial methodology of my PhD?\")\n",
    "    \n",
    "    try:\n",
    "        # Using invoke_prompt correctly for the current SDK version\n",
    "        result = await kernel.invoke_prompt(\n",
    "            prompt=prompt_template,\n",
    "            arguments=args\n",
    "        )\n",
    "        print(f\"\\n✅ FINAL ANSWER:\\n\\n{result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ KERNEL ERROR: {e}\")\n",
    "\n",
    "# Run it\n",
    "await quick_chat_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5ba28353",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chat_service' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      7\u001b[39m kernel = sk.Kernel()\n\u001b[32m      8\u001b[39m kernel.add_service(AzureChatCompletion(\n\u001b[32m      9\u001b[39m     deployment_name=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     endpoint=\u001b[33m\"\u001b[39m\u001b[33mhttps://phd-agent-ukef-resource.services.ai.azure.com/api/projects/phd_agent_ukef\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;66;03m# e.g., https://resourcename.openai.azure.com/\u001b[39;00m\n\u001b[32m     11\u001b[39m     api_key=\u001b[33m\"\u001b[39m\u001b[33mB0SPovWEZIqO8KRrfIOUQzG3YuF2VAU2T8GLVQtPMXzuIKGcBxaOJQQJ99CAACfhMk5XJ3w3AAAAACOGRNqh\u001b[39m\u001b[33m\"\u001b[39m,    \u001b[38;5;66;03m# The actual 32-character key\u001b[39;00m\n\u001b[32m     12\u001b[39m     api_version=\u001b[33m\"\u001b[39m\u001b[33m2024-02-01\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# <--- This is the fix for the 400 error\u001b[39;00m\n\u001b[32m     13\u001b[39m ))\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m kernel.add_service(\u001b[43mchat_service\u001b[49m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfinalize_phd_methodology\u001b[39m():\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🚀 Attempting final invocation with stable API version...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'chat_service' is not defined"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "# 1. THE CORE SETUP (Using your API Key directly)\n",
    "# This eliminates the \"Audience\" error entirely\n",
    "kernel = sk.Kernel()\n",
    "kernel.add_service(AzureChatCompletion(\n",
    "    deployment_name=\"gpt-4o\",\n",
    "    endpoint=\"https://phd-agent-ukef-resource.services.ai.azure.com/api/projects/phd_agent_ukef\", # e.g., https://resourcename.openai.azure.com/\n",
    "    api_key=\"B0SPovWEZIqO8KRrfIOUQzG3YuF2VAU2T8GLVQtPMXzuIKGcBxaOJQQJ99CAACfhMk5XJ3w3AAAAACOGRNqh\",    # The actual 32-character key\n",
    "    api_version=\"2024-02-01\" # <--- This is the fix for the 400 error\n",
    "))\n",
    "\n",
    "kernel.add_service(chat_service)\n",
    "\n",
    "async def finalize_phd_methodology():\n",
    "    print(\"🚀 Attempting final invocation with stable API version...\")\n",
    "    \n",
    "    # Using the SK template syntax\n",
    "    prompt = \"\"\"\n",
    "    Analyze the following research intersection:\n",
    "    UKEF Mandate: 'No Net Cost' (Break-even over the long term)\n",
    "    PhD Goal: {{ $input }}\n",
    "    \n",
    "    Provide a methodology paragraph that explains how the 'No Net Cost' \n",
    "    constraint will be modeled as a boundary condition in the financial simulations.\n",
    "    \"\"\"\n",
    "    \n",
    "    args = KernelArguments(input=\"Developing a risk-adjusted discount rate for sustainable infrastructure.\")\n",
    "    \n",
    "    try:\n",
    "        result = await kernel.invoke_prompt(\n",
    "            prompt=prompt,\n",
    "            arguments=args\n",
    "        )\n",
    "        print(\"\\n✅ SUCCESS! THESIS CONTENT GENERATED:\\n\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ KERNEL ERROR: {e}\")\n",
    "        print(\"\\n💡 Check: Is your deployment name actually 'gpt-4o' or something else like 'my-gpt4'?\")\n",
    "\n",
    "await finalize_phd_methodology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37c9372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a52cbad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_info = cred.get_token(\"https://cognitiveservices.azure.com/.default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cd1dbc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DefaultAzureCredential failed to retrieve a token from the included credentials.\n",
      "Attempted credentials:\n",
      "\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\n",
      "Visit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.\n",
      "\tWorkloadIdentityCredential: WorkloadIdentityCredential authentication unavailable. The workload options are not fully configured. See the troubleshooting guide for more information: https://aka.ms/azsdk/python/identity/workloadidentitycredential/troubleshoot. Missing required arguments: 'tenant_id', 'client_id', 'token_file_path'.\n",
      "\tManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no response from the IMDS endpoint. Token request error: (invalid_request) Identity not found\n",
      "\tSharedTokenCacheCredential: SharedTokenCacheCredential authentication unavailable. No accounts were found in the cache.\n",
      "\tVisualStudioCodeCredential: VisualStudioCodeCredential requires the 'azure-identity-broker' package to be installed. You must also ensure you have the Azure Resources extension installed and have signed in to Azure via Visual Studio Code.\n",
      "\tAzureCliCredential: ERROR: AADSTS500011: The resource principal named https://ai.openai.azure.com was not found in the tenant named University of Salford. This can happen if the application has not been installed by the administrator of the tenant or consented to by any user in the tenant. You might have sent your authentication request to the wrong tenant. Trace ID: 091df3e1-4a98-4835-88d4-d9cd70cd1900 Correlation ID: 76ce04fb-8f65-41fc-a10d-299a9d7e66c2 Timestamp: 2026-01-25 21:51:52Z\n",
      "Run the command below to authenticate interactively; additional arguments may be added as needed:\n",
      "az logout\n",
      "az login --tenant \"65b52940-f4b6-41bd-833d-3033ecbcf6e1\" --scope \"https://ai.openai.azure.com/.default\"\n",
      "\n",
      "\tAzurePowerShellCredential: PowerShell is not installed\n",
      "\tAzureDeveloperCliCredential: Azure Developer CLI could not be found. Please visit https://aka.ms/azure-dev for installation instructions and then,once installed, authenticate to your Azure account using 'azd auth login'.\n",
      "\tBrokerCredential: InteractiveBrowserBrokerCredential unavailable. The 'azure-identity-broker' package is required to use brokered authentication.\n",
      "To mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.\n"
     ]
    },
    {
     "ename": "ClientAuthenticationError",
     "evalue": "DefaultAzureCredential failed to retrieve a token from the included credentials.\nAttempted credentials:\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\nVisit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.\n\tWorkloadIdentityCredential: WorkloadIdentityCredential authentication unavailable. The workload options are not fully configured. See the troubleshooting guide for more information: https://aka.ms/azsdk/python/identity/workloadidentitycredential/troubleshoot. Missing required arguments: 'tenant_id', 'client_id', 'token_file_path'.\n\tManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no response from the IMDS endpoint. Token request error: (invalid_request) Identity not found\n\tSharedTokenCacheCredential: SharedTokenCacheCredential authentication unavailable. No accounts were found in the cache.\n\tVisualStudioCodeCredential: VisualStudioCodeCredential requires the 'azure-identity-broker' package to be installed. You must also ensure you have the Azure Resources extension installed and have signed in to Azure via Visual Studio Code.\n\tAzureCliCredential: ERROR: AADSTS500011: The resource principal named https://ai.openai.azure.com was not found in the tenant named University of Salford. This can happen if the application has not been installed by the administrator of the tenant or consented to by any user in the tenant. You might have sent your authentication request to the wrong tenant. Trace ID: 091df3e1-4a98-4835-88d4-d9cd70cd1900 Correlation ID: 76ce04fb-8f65-41fc-a10d-299a9d7e66c2 Timestamp: 2026-01-25 21:51:52Z\nRun the command below to authenticate interactively; additional arguments may be added as needed:\naz logout\naz login --tenant \"65b52940-f4b6-41bd-833d-3033ecbcf6e1\" --scope \"https://ai.openai.azure.com/.default\"\n\n\tAzurePowerShellCredential: PowerShell is not installed\n\tAzureDeveloperCliCredential: Azure Developer CLI could not be found. Please visit https://aka.ms/azure-dev for installation instructions and then,once installed, authenticate to your Azure account using 'azd auth login'.\n\tBrokerCredential: InteractiveBrowserBrokerCredential unavailable. The 'azure-identity-broker' package is required to use brokered authentication.\nTo mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientAuthenticationError\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Correct scope for Azure OpenAI\u001b[39;00m\n\u001b[32m      6\u001b[39m cred = DefaultAzureCredential()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m token_info = \u001b[43mcred\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_token\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://ai.openai.azure.com/.default\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m access_token = token_info.token\n\u001b[32m     10\u001b[39m kernel = sk.Kernel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/azure/identity/_credentials/default.py:344\u001b[39m, in \u001b[36mDefaultAzureCredential.get_token\u001b[39m\u001b[34m(self, claims, tenant_id, *scopes, **kwargs)\u001b[39m\n\u001b[32m    342\u001b[39m within_dac.set(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     token = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclaims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclaims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    346\u001b[39m     within_dac.set(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/azure/identity/_credentials/chained.py:159\u001b[39m, in \u001b[36mChainedTokenCredential.get_token\u001b[39m\u001b[34m(self, claims, tenant_id, enable_cae, *scopes, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m message = (\n\u001b[32m    152\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\n\u001b[32m    153\u001b[39m     + \u001b[33m\"\u001b[39m\u001b[33m failed to retrieve a token from the included credentials.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttps://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m )\n\u001b[32m    158\u001b[39m _LOGGER.warning(message)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ClientAuthenticationError(message=message)\n",
      "\u001b[31mClientAuthenticationError\u001b[39m: DefaultAzureCredential failed to retrieve a token from the included credentials.\nAttempted credentials:\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\nVisit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.\n\tWorkloadIdentityCredential: WorkloadIdentityCredential authentication unavailable. The workload options are not fully configured. See the troubleshooting guide for more information: https://aka.ms/azsdk/python/identity/workloadidentitycredential/troubleshoot. Missing required arguments: 'tenant_id', 'client_id', 'token_file_path'.\n\tManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no response from the IMDS endpoint. Token request error: (invalid_request) Identity not found\n\tSharedTokenCacheCredential: SharedTokenCacheCredential authentication unavailable. No accounts were found in the cache.\n\tVisualStudioCodeCredential: VisualStudioCodeCredential requires the 'azure-identity-broker' package to be installed. You must also ensure you have the Azure Resources extension installed and have signed in to Azure via Visual Studio Code.\n\tAzureCliCredential: ERROR: AADSTS500011: The resource principal named https://ai.openai.azure.com was not found in the tenant named University of Salford. This can happen if the application has not been installed by the administrator of the tenant or consented to by any user in the tenant. You might have sent your authentication request to the wrong tenant. Trace ID: 091df3e1-4a98-4835-88d4-d9cd70cd1900 Correlation ID: 76ce04fb-8f65-41fc-a10d-299a9d7e66c2 Timestamp: 2026-01-25 21:51:52Z\nRun the command below to authenticate interactively; additional arguments may be added as needed:\naz logout\naz login --tenant \"65b52940-f4b6-41bd-833d-3033ecbcf6e1\" --scope \"https://ai.openai.azure.com/.default\"\n\n\tAzurePowerShellCredential: PowerShell is not installed\n\tAzureDeveloperCliCredential: Azure Developer CLI could not be found. Please visit https://aka.ms/azure-dev for installation instructions and then,once installed, authenticate to your Azure account using 'azd auth login'.\n\tBrokerCredential: InteractiveBrowserBrokerCredential unavailable. The 'azure-identity-broker' package is required to use brokered authentication.\nTo mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot."
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "# Correct scope for Azure OpenAI\n",
    "cred = DefaultAzureCredential()\n",
    "token_info = cred.get_token(\"https://ai.openai.azure.com/.default\")\n",
    "access_token = token_info.token\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        deployment_name=\"gpt-4o\",\n",
    "        endpoint=clean_endpoint,\n",
    "        api_key=None,               # don't pass token here\n",
    "        azure_oai_token=access_token  # correct way\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "93d4ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        deployment_name=\"gpt-4o\",  # must match the deployment in abphd\n",
    "        endpoint=\"https://abphd.openai.azure.com/\",  # ✅ base endpoint\n",
    "        api_key=\"5HWUIJ5yCaW3XPJCzdv4lt63mGC1T5K5pBciBZk3qrtNZ4tVXpxhJQQJ99CAACYeBjFXJ3w3AAABACOGZNFP\"  # ✅ use Key1\n",
    "    ),\n",
    "    overwrite=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6c543e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing agents: ['agent_ukef', 'agent_phd']\n"
     ]
    }
   ],
   "source": [
    "existing_agents = [name for name in [\"agent_ukef\", \"agent_phd\"] if name in globals()]\n",
    "print(\"Existing agents:\", existing_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "876f4bc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[110]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msemantic_kernel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnectors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopen_ai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIPromptExecutionSettings\n\u001b[32m      3\u001b[39m settings = OpenAIPromptExecutionSettings(\n\u001b[32m      4\u001b[39m     messages=[{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mHello! Can you respond to this message?\u001b[39m\u001b[33m\"\u001b[39m}],\n\u001b[32m      5\u001b[39m     max_tokens=\u001b[32m500\u001b[39m\n\u001b[32m      6\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m chat_service.get_chat_message_contents(\n\u001b[32m      9\u001b[39m     chat_history=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     10\u001b[39m     settings=settings\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(msg.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/chat_completion_client_base.py:134\u001b[39m, in \u001b[36mChatCompletionClientBase.get_chat_message_contents\u001b[39m\u001b[34m(self, chat_history, settings, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m     settings.function_choice_behavior.configure(\n\u001b[32m    125\u001b[39m         kernel=kernel,\n\u001b[32m    126\u001b[39m         update_settings_callback=\u001b[38;5;28mself\u001b[39m._update_function_choice_settings_callback(),\n\u001b[32m    127\u001b[39m         settings=settings,\n\u001b[32m    128\u001b[39m     )\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    131\u001b[39m     settings.function_choice_behavior \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    132\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m settings.function_choice_behavior.auto_invoke_kernel_functions\n\u001b[32m    133\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_get_chat_message_contents(chat_history, settings)\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# Auto invoke loop\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m use_span(\u001b[38;5;28mself\u001b[39m._start_auto_function_invocation_activity(kernel, settings), end_on_exit=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m _:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/utils/telemetry/model_diagnostics/decorators.py:110\u001b[39m, in \u001b[36mtrace_chat_completion.<locals>.inner_trace_chat_completion.<locals>.wrapper_decorator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(completion_func)\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_decorator\u001b[39m(*args: Any, **kwargs: Any) -> \u001b[38;5;28mlist\u001b[39m[ChatMessageContent]:\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n\u001b[32m    109\u001b[39m         \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m completion_func(*args, **kwargs)\n\u001b[32m    112\u001b[39m     completion_service: \u001b[33m\"\u001b[39m\u001b[33mChatCompletionClientBase\u001b[39m\u001b[33m\"\u001b[39m = args[\u001b[32m0\u001b[39m]\n\u001b[32m    113\u001b[39m     chat_history: ChatHistory = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mchat_history\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_chat_completion_base.py:85\u001b[39m, in \u001b[36mOpenAIChatCompletionBase._inner_get_chat_message_contents\u001b[39m\u001b[34m(self, chat_history, settings)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIChatPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[32m     84\u001b[39m settings.stream = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m settings.messages = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_chat_history_for_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat_history\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m settings.ai_model_id = settings.ai_model_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_id\n\u001b[32m     88\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_request(settings)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_chat_completion_base.py:301\u001b[39m, in \u001b[36mOpenAIChatCompletionBase._prepare_chat_history_for_request\u001b[39m\u001b[34m(self, chat_history, role_key, content_key)\u001b[39m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prepare_chat_history_for_request\u001b[39m(\n\u001b[32m    271\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    272\u001b[39m     chat_history: \u001b[33m\"\u001b[39m\u001b[33mChatHistory\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    273\u001b[39m     role_key: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    274\u001b[39m     content_key: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    275\u001b[39m ) -> Any:\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Prepare the chat history for a request.\u001b[39;00m\n\u001b[32m    277\u001b[39m \n\u001b[32m    278\u001b[39m \u001b[33;03m    Allowing customization of the key names for role/author, and optionally overriding the role.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    292\u001b[39m \u001b[33;03m        prepared_chat_history (Any): The prepared chat history for a request.\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    295\u001b[39m         {\n\u001b[32m    296\u001b[39m             **message.to_dict(role_key=role_key, content_key=content_key),\n\u001b[32m    297\u001b[39m             role_key: \u001b[33m\"\u001b[39m\u001b[33mdeveloper\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    298\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.instruction_role == \u001b[33m\"\u001b[39m\u001b[33mdeveloper\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m message.to_dict(role_key=role_key)[role_key] == \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    299\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m message.to_dict(role_key=role_key)[role_key],\n\u001b[32m    300\u001b[39m         }\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[43mchat_history\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\n\u001b[32m    302\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, (AnnotationContent, FileReferenceContent))\n\u001b[32m    303\u001b[39m     ]\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'messages'"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import OpenAIPromptExecutionSettings\n",
    "\n",
    "settings = OpenAIPromptExecutionSettings(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello! Can you respond to this message?\"}],\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "response = await chat_service.get_chat_message_contents(\n",
    "    chat_history=None,\n",
    "    settings=settings\n",
    ")\n",
    "\n",
    "for msg in response:\n",
    "    print(msg.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "de5d1ab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'semantic_kernel.chat_history'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[112]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msemantic_kernel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Kernel\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msemantic_kernel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnectors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopen_ai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatCompletion, OpenAIPromptExecutionSettings\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msemantic_kernel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_history\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatHistory  \u001b[38;5;66;03m# ✅ Correct import\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01masyncio\u001b[39;00m\n\u001b[32m      6\u001b[39m kernel = Kernel()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'semantic_kernel.chat_history'"
     ]
    }
   ],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIPromptExecutionSettings\n",
    "from semantic_kernel.chat_history import ChatHistory  # ✅ Correct import\n",
    "import asyncio\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "# Add Azure Chat Completion service\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        deployment_name=\"gpt-4o\",\n",
    "        endpoint=\"https://abphd.openai.azure.com/\",\n",
    "        api_key=\"5HWUIJ5yCaW3XPJCzdv4lt63mGC1T5K5pBciBZk3qrtNZ4tVXpxhJQQJ99CAACYeBjFXJ3w3AAABACOGZNFP\"\n",
    "    ),\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "kernel.add_service(chat_service, overwrite=True)\n",
    "\n",
    "async def test_chat():\n",
    "    settings = OpenAIPromptExecutionSettings(\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Hello! Can you respond to this message?\"}],\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    # Chat history is now optional; just omit it\n",
    "    response = await chat_service.get_chat_message_contents(settings=settings)\n",
    "    \n",
    "    for msg in response:\n",
    "        print(msg.content)\n",
    "\n",
    "asyncio.run(test_chat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a6f97051",
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceResponseException",
     "evalue": "(\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", AuthenticationError(\"Error code: 401 - {'error': {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}}\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:88\u001b[39m, in \u001b[36mOpenAIHandler._send_completion_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m     87\u001b[39m         settings_dict.pop(\u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.chat.completions.create(**settings_dict)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:2678\u001b[39m, in \u001b[36mcreate\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2663\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get(\n\u001b[32m   2664\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/chat/completions/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompletion_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   2665\u001b[39m         options=make_request_options(\n\u001b[32m   (...)\u001b[39m\u001b[32m   2668\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m   2669\u001b[39m     )\n\u001b[32m   2671\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate\u001b[39m(\n\u001b[32m   2672\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2673\u001b[39m     completion_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   2674\u001b[39m     *,\n\u001b[32m   2675\u001b[39m     metadata: Optional[Metadata],\n\u001b[32m   2676\u001b[39m     \u001b[38;5;66;03m# Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.\u001b[39;00m\n\u001b[32m   2677\u001b[39m     \u001b[38;5;66;03m# The extra values given here take precedence over values defined on the client or passed to this method.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2678\u001b[39m     extra_headers: Headers | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2679\u001b[39m     extra_query: Query | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2680\u001b[39m     extra_body: Body | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2681\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   2682\u001b[39m ) -> ChatCompletion:\n\u001b[32m   2683\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Modify a stored chat completion.\u001b[39;00m\n\u001b[32m   2684\u001b[39m \n\u001b[32m   2685\u001b[39m \u001b[33;03m    Only Chat Completions that have been created\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2703\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m   2704\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/_base_client.py:1797\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1794\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n\u001b[32m   1796\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpatch\u001b[39m(\n\u001b[32m-> \u001b[39m\u001b[32m1797\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1798\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   1799\u001b[39m     *,\n\u001b[32m   1800\u001b[39m     cast_to: Type[ResponseT],\n\u001b[32m   1801\u001b[39m     body: Body | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1802\u001b[39m     options: RequestOptions = {},\n\u001b[32m   1803\u001b[39m ) -> ResponseT:\n\u001b[32m   1804\u001b[39m     opts = FinalRequestOptions.construct(method=\u001b[33m\"\u001b[39m\u001b[33mpatch\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/_base_client.py:1597\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mServiceResponseException\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[97]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m chat = AgentGroupChat(agents=[test_agent])\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m chat.add_chat_message(\u001b[33m\"\u001b[39m\u001b[33mHello, can you respond to this?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m content \u001b[38;5;129;01min\u001b[39;00m chat.invoke():\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/agents/group_chat/agent_group_chat.py:156\u001b[39m, in \u001b[36mAgentGroupChat.invoke\u001b[39m\u001b[34m(self, agent, is_joining)\u001b[39m\n\u001b[32m    153\u001b[39m     logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to select agent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AgentChatException(\u001b[33m\"\u001b[39m\u001b[33mFailed to select agent\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().invoke_agent(selected_agent):\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m message.role == AuthorRole.ASSISTANT:\n\u001b[32m    158\u001b[39m         task = \u001b[38;5;28mself\u001b[39m.termination_strategy.should_terminate(selected_agent, \u001b[38;5;28mself\u001b[39m.history.messages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/agents/group_chat/agent_chat.py:149\u001b[39m, in \u001b[36mAgentChat.invoke_agent\u001b[39m\u001b[34m(self, agent)\u001b[39m\n\u001b[32m    146\u001b[39m channel: AgentChannel = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_or_create_channel(agent)\n\u001b[32m    147\u001b[39m messages: \u001b[38;5;28mlist\u001b[39m[ChatMessageContent] = []\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m is_visible, message \u001b[38;5;129;01min\u001b[39;00m channel.invoke(agent):\n\u001b[32m    150\u001b[39m     messages.append(message)\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.history.messages.append(message)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/agents/channels/chat_history_channel.py:65\u001b[39m, in \u001b[36mChatHistoryChannel.invoke\u001b[39m\u001b[34m(self, agent, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m mutated_history = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m     63\u001b[39m message_queue: Deque[ChatMessageContent] = deque()\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m agent.invoke(\n\u001b[32m     66\u001b[39m     messages=\u001b[38;5;28mself\u001b[39m.messages[-\u001b[32m1\u001b[39m],\n\u001b[32m     67\u001b[39m     thread=\u001b[38;5;28mself\u001b[39m.thread,\n\u001b[32m     68\u001b[39m ):\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# Capture all messages that have been included in the mutated history.\u001b[39;00m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m message_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(message_count, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.messages)):\n\u001b[32m     71\u001b[39m         mutated_message = \u001b[38;5;28mself\u001b[39m.messages[message_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/utils/telemetry/agent_diagnostics/decorators.py:106\u001b[39m, in \u001b[36mtrace_agent_invocation.<locals>.wrapper_decorator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(invoke_func)\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_decorator\u001b[39m(\n\u001b[32m    101\u001b[39m     *args: P.args,\n\u001b[32m    102\u001b[39m     **kwargs: P.kwargs,\n\u001b[32m    103\u001b[39m ) -> AsyncIterable[AgentResponseItem[ChatMessageContent]]:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n\u001b[32m    105\u001b[39m         \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the responses\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m invoke_func(*args, **kwargs):\n\u001b[32m    107\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m response\n\u001b[32m    108\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/agents/chat_completion/chat_completion_agent.py:364\u001b[39m, in \u001b[36mChatCompletionAgent.invoke\u001b[39m\u001b[34m(self, messages, thread, on_intermediate_message, arguments, kernel, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m thread.get_messages():\n\u001b[32m    362\u001b[39m     chat_history.add_message(message)\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_invoke(\n\u001b[32m    365\u001b[39m     thread,\n\u001b[32m    366\u001b[39m     chat_history,\n\u001b[32m    367\u001b[39m     on_intermediate_message,\n\u001b[32m    368\u001b[39m     arguments,\n\u001b[32m    369\u001b[39m     kernel,\n\u001b[32m    370\u001b[39m     **kwargs,\n\u001b[32m    371\u001b[39m ):\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m AgentResponseItem(message=response, thread=thread)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/agents/chat_completion/chat_completion_agent.py:537\u001b[39m, in \u001b[36mChatCompletionAgent._inner_invoke\u001b[39m\u001b[34m(self, thread, history, on_intermediate_message, arguments, kernel, **kwargs)\u001b[39m\n\u001b[32m    533\u001b[39m message_count_before_completion = \u001b[38;5;28mlen\u001b[39m(agent_chat_history)\n\u001b[32m    535\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Invoking \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(chat_completion_service).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m responses = \u001b[38;5;28;01mawait\u001b[39;00m chat_completion_service.get_chat_message_contents(\n\u001b[32m    538\u001b[39m     chat_history=agent_chat_history,\n\u001b[32m    539\u001b[39m     settings=settings,\n\u001b[32m    540\u001b[39m     kernel=kernel,\n\u001b[32m    541\u001b[39m     arguments=arguments,\n\u001b[32m    542\u001b[39m )\n\u001b[32m    544\u001b[39m logger.debug(\n\u001b[32m    545\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Invoked \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(chat_completion_service).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    546\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwith message count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage_count_before_completion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    547\u001b[39m )\n\u001b[32m    549\u001b[39m \u001b[38;5;66;03m# Drain newly added tool messages since last index to maintain\u001b[39;00m\n\u001b[32m    550\u001b[39m \u001b[38;5;66;03m# correct order and avoid duplicates\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/chat_completion_client_base.py:139\u001b[39m, in \u001b[36mChatCompletionClientBase.get_chat_message_contents\u001b[39m\u001b[34m(self, chat_history, settings, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m use_span(\u001b[38;5;28mself\u001b[39m._start_auto_function_invocation_activity(kernel, settings), end_on_exit=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m _:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m request_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(settings.function_choice_behavior.maximum_auto_invoke_attempts):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m         completions = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_get_chat_message_contents(chat_history, settings)\n\u001b[32m    140\u001b[39m         \u001b[38;5;66;03m# Get the function call contents from the chat message. There is only one chat message,\u001b[39;00m\n\u001b[32m    141\u001b[39m         \u001b[38;5;66;03m# which should be checked in the `_verify_function_choice_settings` method.\u001b[39;00m\n\u001b[32m    142\u001b[39m         function_calls = [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m completions[\u001b[32m0\u001b[39m].items \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, FunctionCallContent)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/utils/telemetry/model_diagnostics/decorators.py:110\u001b[39m, in \u001b[36mtrace_chat_completion.<locals>.inner_trace_chat_completion.<locals>.wrapper_decorator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(completion_func)\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_decorator\u001b[39m(*args: Any, **kwargs: Any) -> \u001b[38;5;28mlist\u001b[39m[ChatMessageContent]:\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n\u001b[32m    109\u001b[39m         \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m completion_func(*args, **kwargs)\n\u001b[32m    112\u001b[39m     completion_service: \u001b[33m\"\u001b[39m\u001b[33mChatCompletionClientBase\u001b[39m\u001b[33m\"\u001b[39m = args[\u001b[32m0\u001b[39m]\n\u001b[32m    113\u001b[39m     chat_history: ChatHistory = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mchat_history\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_chat_completion_base.py:88\u001b[39m, in \u001b[36mOpenAIChatCompletionBase._inner_get_chat_message_contents\u001b[39m\u001b[34m(self, chat_history, settings)\u001b[39m\n\u001b[32m     85\u001b[39m settings.messages = \u001b[38;5;28mself\u001b[39m._prepare_chat_history_for_request(chat_history)\n\u001b[32m     86\u001b[39m settings.ai_model_id = settings.ai_model_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_id\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_request(settings)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, ChatCompletion)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[32m     90\u001b[39m response_metadata = \u001b[38;5;28mself\u001b[39m._get_metadata_from_chat_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:60\u001b[39m, in \u001b[36mOpenAIHandler._send_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.TEXT \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.CHAT:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_completion_request(settings)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.EMBEDDING:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIEmbeddingPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:105\u001b[39m, in \u001b[36mOpenAIHandler._send_completion_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[32m    101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service failed to complete the prompt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    102\u001b[39m         ex,\n\u001b[32m    103\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[32m    106\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service failed to complete the prompt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    107\u001b[39m         ex,\n\u001b[32m    108\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n",
      "\u001b[31mServiceResponseException\u001b[39m: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", AuthenticationError(\"Error code: 401 - {'error': {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}}\"))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/pygments/regexopt.py:26: RuntimeWarning: coroutine 'final_test' was never awaited\n",
      "  def regex_opt_inner(strings, open_paren):\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# Minimal test agent\n",
    "test_agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"TestAgent\",\n",
    "    instructions=\"You are a helpful assistant. Respond concisely.\"\n",
    ")\n",
    "\n",
    "chat = AgentGroupChat(agents=[test_agent])\n",
    "await chat.add_chat_message(\"Hello, can you respond to this?\")\n",
    "async for content in chat.invoke():\n",
    "    print(f\"[{content.name}]: {content.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3de2e4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing services in kernel:\n",
      " - gpt-4o: AzureChatCompletion\n"
     ]
    }
   ],
   "source": [
    "# List all currently added services\n",
    "if kernel.services:\n",
    "    print(\"Existing services in kernel:\")\n",
    "    for service_id, service in kernel.services.items():\n",
    "        print(f\" - {service_id}: {type(service).__name__}\")\n",
    "else:\n",
    "    print(\"No services have been added yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e625a7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing agents: ['agent_ukef', 'agent_phd']\n",
      "🚀 Attempting Multi-Agent Chat...\n"
     ]
    },
    {
     "ename": "ServiceResponseException",
     "evalue": "(\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", AuthenticationError(\"Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://ai.azure.com), or have expired.'}\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:88\u001b[39m, in \u001b[36mOpenAIHandler._send_completion_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m     87\u001b[39m         settings_dict.pop(\u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.chat.completions.create(**settings_dict)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:2678\u001b[39m, in \u001b[36mcreate\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2663\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get(\n\u001b[32m   2664\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/chat/completions/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompletion_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   2665\u001b[39m         options=make_request_options(\n\u001b[32m   (...)\u001b[39m\u001b[32m   2668\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m   2669\u001b[39m     )\n\u001b[32m   2671\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate\u001b[39m(\n\u001b[32m   2672\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2673\u001b[39m     completion_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   2674\u001b[39m     *,\n\u001b[32m   2675\u001b[39m     metadata: Optional[Metadata],\n\u001b[32m   2676\u001b[39m     \u001b[38;5;66;03m# Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.\u001b[39;00m\n\u001b[32m   2677\u001b[39m     \u001b[38;5;66;03m# The extra values given here take precedence over values defined on the client or passed to this method.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2678\u001b[39m     extra_headers: Headers | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2679\u001b[39m     extra_query: Query | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2680\u001b[39m     extra_body: Body | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2681\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   2682\u001b[39m ) -> ChatCompletion:\n\u001b[32m   2683\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Modify a stored chat completion.\u001b[39;00m\n\u001b[32m   2684\u001b[39m \n\u001b[32m   2685\u001b[39m \u001b[33;03m    Only Chat Completions that have been created\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2703\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m   2704\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/_base_client.py:1797\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1794\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n\u001b[32m   1796\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpatch\u001b[39m(\n\u001b[32m-> \u001b[39m\u001b[32m1797\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1798\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   1799\u001b[39m     *,\n\u001b[32m   1800\u001b[39m     cast_to: Type[ResponseT],\n\u001b[32m   1801\u001b[39m     body: Body | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1802\u001b[39m     options: RequestOptions = {},\n\u001b[32m   1803\u001b[39m ) -> ResponseT:\n\u001b[32m   1804\u001b[39m     opts = FinalRequestOptions.construct(method=\u001b[33m\"\u001b[39m\u001b[33mpatch\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/_base_client.py:1597\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://ai.azure.com), or have expired.'}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mServiceResponseException\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m content \u001b[38;5;129;01min\u001b[39;00m chat.invoke():\n\u001b[32m     35\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m final_test()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mfinal_test\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m chat.add_chat_message(query)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🚀 Attempting Multi-Agent Chat...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m content \u001b[38;5;129;01min\u001b[39;00m chat.invoke():\n\u001b[32m     35\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/agents/group_chat/agent_group_chat.py:156\u001b[39m, in \u001b[36mAgentGroupChat.invoke\u001b[39m\u001b[34m(self, agent, is_joining)\u001b[39m\n\u001b[32m    153\u001b[39m     logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to select agent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AgentChatException(\u001b[33m\"\u001b[39m\u001b[33mFailed to select agent\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().invoke_agent(selected_agent):\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m message.role == AuthorRole.ASSISTANT:\n\u001b[32m    158\u001b[39m         task = \u001b[38;5;28mself\u001b[39m.termination_strategy.should_terminate(selected_agent, \u001b[38;5;28mself\u001b[39m.history.messages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/agents/group_chat/agent_chat.py:149\u001b[39m, in \u001b[36mAgentChat.invoke_agent\u001b[39m\u001b[34m(self, agent)\u001b[39m\n\u001b[32m    146\u001b[39m channel: AgentChannel = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_or_create_channel(agent)\n\u001b[32m    147\u001b[39m messages: \u001b[38;5;28mlist\u001b[39m[ChatMessageContent] = []\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m is_visible, message \u001b[38;5;129;01min\u001b[39;00m channel.invoke(agent):\n\u001b[32m    150\u001b[39m     messages.append(message)\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.history.messages.append(message)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/agents/channels/chat_history_channel.py:65\u001b[39m, in \u001b[36mChatHistoryChannel.invoke\u001b[39m\u001b[34m(self, agent, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m mutated_history = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m     63\u001b[39m message_queue: Deque[ChatMessageContent] = deque()\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m agent.invoke(\n\u001b[32m     66\u001b[39m     messages=\u001b[38;5;28mself\u001b[39m.messages[-\u001b[32m1\u001b[39m],\n\u001b[32m     67\u001b[39m     thread=\u001b[38;5;28mself\u001b[39m.thread,\n\u001b[32m     68\u001b[39m ):\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# Capture all messages that have been included in the mutated history.\u001b[39;00m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m message_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(message_count, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.messages)):\n\u001b[32m     71\u001b[39m         mutated_message = \u001b[38;5;28mself\u001b[39m.messages[message_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/utils/telemetry/agent_diagnostics/decorators.py:106\u001b[39m, in \u001b[36mtrace_agent_invocation.<locals>.wrapper_decorator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(invoke_func)\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_decorator\u001b[39m(\n\u001b[32m    101\u001b[39m     *args: P.args,\n\u001b[32m    102\u001b[39m     **kwargs: P.kwargs,\n\u001b[32m    103\u001b[39m ) -> AsyncIterable[AgentResponseItem[ChatMessageContent]]:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n\u001b[32m    105\u001b[39m         \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the responses\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m invoke_func(*args, **kwargs):\n\u001b[32m    107\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m response\n\u001b[32m    108\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/agents/chat_completion/chat_completion_agent.py:364\u001b[39m, in \u001b[36mChatCompletionAgent.invoke\u001b[39m\u001b[34m(self, messages, thread, on_intermediate_message, arguments, kernel, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m thread.get_messages():\n\u001b[32m    362\u001b[39m     chat_history.add_message(message)\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_invoke(\n\u001b[32m    365\u001b[39m     thread,\n\u001b[32m    366\u001b[39m     chat_history,\n\u001b[32m    367\u001b[39m     on_intermediate_message,\n\u001b[32m    368\u001b[39m     arguments,\n\u001b[32m    369\u001b[39m     kernel,\n\u001b[32m    370\u001b[39m     **kwargs,\n\u001b[32m    371\u001b[39m ):\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m AgentResponseItem(message=response, thread=thread)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/agents/chat_completion/chat_completion_agent.py:537\u001b[39m, in \u001b[36mChatCompletionAgent._inner_invoke\u001b[39m\u001b[34m(self, thread, history, on_intermediate_message, arguments, kernel, **kwargs)\u001b[39m\n\u001b[32m    533\u001b[39m message_count_before_completion = \u001b[38;5;28mlen\u001b[39m(agent_chat_history)\n\u001b[32m    535\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Invoking \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(chat_completion_service).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m responses = \u001b[38;5;28;01mawait\u001b[39;00m chat_completion_service.get_chat_message_contents(\n\u001b[32m    538\u001b[39m     chat_history=agent_chat_history,\n\u001b[32m    539\u001b[39m     settings=settings,\n\u001b[32m    540\u001b[39m     kernel=kernel,\n\u001b[32m    541\u001b[39m     arguments=arguments,\n\u001b[32m    542\u001b[39m )\n\u001b[32m    544\u001b[39m logger.debug(\n\u001b[32m    545\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Invoked \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(chat_completion_service).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    546\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwith message count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage_count_before_completion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    547\u001b[39m )\n\u001b[32m    549\u001b[39m \u001b[38;5;66;03m# Drain newly added tool messages since last index to maintain\u001b[39;00m\n\u001b[32m    550\u001b[39m \u001b[38;5;66;03m# correct order and avoid duplicates\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/chat_completion_client_base.py:139\u001b[39m, in \u001b[36mChatCompletionClientBase.get_chat_message_contents\u001b[39m\u001b[34m(self, chat_history, settings, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m use_span(\u001b[38;5;28mself\u001b[39m._start_auto_function_invocation_activity(kernel, settings), end_on_exit=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m _:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m request_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(settings.function_choice_behavior.maximum_auto_invoke_attempts):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m         completions = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_get_chat_message_contents(chat_history, settings)\n\u001b[32m    140\u001b[39m         \u001b[38;5;66;03m# Get the function call contents from the chat message. There is only one chat message,\u001b[39;00m\n\u001b[32m    141\u001b[39m         \u001b[38;5;66;03m# which should be checked in the `_verify_function_choice_settings` method.\u001b[39;00m\n\u001b[32m    142\u001b[39m         function_calls = [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m completions[\u001b[32m0\u001b[39m].items \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, FunctionCallContent)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/utils/telemetry/model_diagnostics/decorators.py:110\u001b[39m, in \u001b[36mtrace_chat_completion.<locals>.inner_trace_chat_completion.<locals>.wrapper_decorator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(completion_func)\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_decorator\u001b[39m(*args: Any, **kwargs: Any) -> \u001b[38;5;28mlist\u001b[39m[ChatMessageContent]:\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n\u001b[32m    109\u001b[39m         \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m completion_func(*args, **kwargs)\n\u001b[32m    112\u001b[39m     completion_service: \u001b[33m\"\u001b[39m\u001b[33mChatCompletionClientBase\u001b[39m\u001b[33m\"\u001b[39m = args[\u001b[32m0\u001b[39m]\n\u001b[32m    113\u001b[39m     chat_history: ChatHistory = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mchat_history\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_chat_completion_base.py:88\u001b[39m, in \u001b[36mOpenAIChatCompletionBase._inner_get_chat_message_contents\u001b[39m\u001b[34m(self, chat_history, settings)\u001b[39m\n\u001b[32m     85\u001b[39m settings.messages = \u001b[38;5;28mself\u001b[39m._prepare_chat_history_for_request(chat_history)\n\u001b[32m     86\u001b[39m settings.ai_model_id = settings.ai_model_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_id\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_request(settings)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, ChatCompletion)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[32m     90\u001b[39m response_metadata = \u001b[38;5;28mself\u001b[39m._get_metadata_from_chat_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:60\u001b[39m, in \u001b[36mOpenAIHandler._send_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.TEXT \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.CHAT:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_completion_request(settings)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.EMBEDDING:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIEmbeddingPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:105\u001b[39m, in \u001b[36mOpenAIHandler._send_completion_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[32m    101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service failed to complete the prompt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    102\u001b[39m         ex,\n\u001b[32m    103\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[32m    106\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service failed to complete the prompt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    107\u001b[39m         ex,\n\u001b[32m    108\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n",
      "\u001b[31mServiceResponseException\u001b[39m: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", AuthenticationError(\"Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://ai.azure.com), or have expired.'}\"))"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.agents import ChatCompletionAgent, AgentGroupChat\n",
    "import asyncio\n",
    "\n",
    "# --- 1. Check if agents already exist ---\n",
    "existing_agents = []\n",
    "for name in [\"agent_ukef\", \"agent_phd\"]:\n",
    "    if name in globals():\n",
    "        existing_agents.append(name)\n",
    "\n",
    "print(f\"Existing agents: {existing_agents}\")\n",
    "\n",
    "# --- 2. Create missing agents ---\n",
    "if \"agent_ukef\" not in existing_agents:\n",
    "    agent_ukef = ChatCompletionAgent(\n",
    "        kernel=kernel,\n",
    "        name=\"UKEF_Expert\",\n",
    "        instructions=\"You are a UKEF expert. Explain 'No Net Cost' and project coverage.\"\n",
    "    )\n",
    "\n",
    "if \"agent_phd\" not in existing_agents:\n",
    "    agent_phd = ChatCompletionAgent(\n",
    "        kernel=kernel,\n",
    "        name=\"PhD_Supervisor\",\n",
    "        instructions=\"You are a PhD Lead. Help apply finance rules to academic research.\"\n",
    "    )\n",
    "\n",
    "# --- 3. Run multi-agent chat ---\n",
    "async def final_test():\n",
    "    chat = AgentGroupChat(agents=[agent_ukef, agent_phd])\n",
    "    query = \"How can I include UKEF's 'No Net Cost' mandate into the financial methodology of my PhD?\"\n",
    "    await chat.add_chat_message(query)\n",
    "    print(\"🚀 Attempting Multi-Agent Chat...\")\n",
    "\n",
    "    async for content in chat.invoke():\n",
    "        print(f\"\\n[{content.name}]: {content.content}\")\n",
    "\n",
    "await final_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a73e314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 GPT-4o-Mini Response:\n",
      "\n",
      "The UKEF (UK Export Finance) 'No Net Cost' mandate is considered a 'solvency-based constraint' for a PhD methodology because it requires that any financial support or guarantees provided by UKEF must not result in a net loss to the government. This means that the financial viability and sustainability of projects must be assessed in a way that ensures the expected revenues or benefits will at least cover the costs associated with the support provided.\n",
      "\n",
      "In the context of a PhD methodology, this constraint necessitates a rigorous evaluation of the economic impacts, risks, and financial models associated with the research. Researchers must demonstrate that their proposed projects are not only feasible but also financially sound, ensuring that they can achieve a positive net outcome. This focus on solvency influences the design of the research, the selection of case studies, and the analytical frameworks used, as the methodology must align with the principles of financial prudence and accountability mandated by UKEF.\n"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIPromptExecutionSettings\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# Updated for gpt-4o-mini\n",
    "chat_service = AzureChatCompletion(\n",
    "    deployment_name=\"gpt-4o-mini\",  # Make sure this matches your Azure Deployment Name\n",
    "    endpoint=\"https://abphd.openai.azure.com/\",\n",
    "    api_key=\"5HWUIJ5yCaW3XPJCzdv4lt63mGC1T5K5pBciBZk3qrtNZ4tVXpxhJQQJ99CAACYeBjFXJ3w3AAABACOGZNFP\",\n",
    "    api_version=\"2024-08-01-preview\" # Updated to a version that fully supports mini's features\n",
    ")\n",
    "\n",
    "kernel.add_service(chat_service)\n",
    "\n",
    "async def test_mini_chat():\n",
    "    history = ChatHistory()\n",
    "    history.add_user_message(\"Briefly explain why the UKEF 'No Net Cost' mandate is a 'solvency-based constraint' for a PhD methodology.\")\n",
    "    \n",
    "    # We use a lower temperature (0.3) for more \"academic\" and precise results\n",
    "    settings = OpenAIPromptExecutionSettings(max_tokens=500, temperature=0.3)\n",
    "    \n",
    "    try:\n",
    "        response = await chat_service.get_chat_message_contents(\n",
    "            chat_history=history,\n",
    "            settings=settings\n",
    "        )\n",
    "        print(\"🤖 GPT-4o-Mini Response:\\n\")\n",
    "        print(response[0].content)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "\n",
    "await test_mini_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "385bd59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏛️ SEMANTIC AGENT RESPONSE:\n",
      "\n",
      "The No Net Cost mandate serves as a critical solvency-based constraint within the context of financial management and economic policy, particularly in the realm of public financing and investment. This mandate stipulates that any financial initiative or project must be designed and executed in such a manner that it does not incur a net cost to the public treasury. In essence, it requires that the financial outlays associated with a project be offset by corresponding revenues or savings, thereby ensuring that the fiscal integrity of the governing body remains intact.\n",
      "\n",
      "From a methodological perspective, the No Net Cost mandate necessitates a rigorous assessment of both the costs and benefits associated with any proposed initiative. This aligns with the principles articulated by Koomey (2011), who emphasizes the importance of efficiency in resource allocation and the need for a comprehensive evaluation of the economic implications of energy-related investments. By adhering to the No Net Cost principle, researchers and policymakers are compelled to adopt a holistic approach to financial analysis, ensuring that all potential revenue streams and cost-saving measures are thoroughly explored and integrated into the project design.\n",
      "\n",
      "Moreover, the application of this mandate can be further elucidated through the lens of Grootendorst (2022), who discusses the implications of financial constraints on project viability and sustainability. The No Net Cost mandate not only serves as a fiscal guideline but also acts as a catalyst for innovation, prompting stakeholders to seek out creative financing solutions and partnerships that can enhance the overall value proposition of a project.\n",
      "\n",
      "In summary, the No Net Cost mandate functions as a solvency-based constraint that requires a meticulous evaluation of financial flows associated with public projects. By ensuring that expenditures are balanced by revenues, this mandate fosters fiscal responsibility and encourages the pursuit of efficiency, ultimately contributing to the sustainability of public finance.\n"
     ]
    }
   ],
   "source": [
    "async def semantic_phd_chat():\n",
    "    history = ChatHistory()\n",
    "    \n",
    "    # 1. THE SEMANTIC \"PERSONA\": This makes it a specialized agent\n",
    "    history.add_system_message(\"\"\"\n",
    "    You are the 'UKEF-PhD Bridge Agent'. Your goal is to help the user integrate \n",
    "    financial mandates into academic research methodology. \n",
    "    \n",
    "    CRITICAL CONSTRAINTS:\n",
    "    - Focus on the 'No Net Cost' mandate as a 'solvency-based constraint'.\n",
    "    - Use formal academic language.\n",
    "    - References to prioritize: Koomey (2011) for efficiency and Grootendorst (2022).\n",
    "    \"\"\")\n",
    "    \n",
    "    # 2. THE USER QUERY\n",
    "    history.add_user_message(\"Explain the No Net Cost mandate as a solvency-based constraint.\")\n",
    "    \n",
    "    settings = OpenAIPromptExecutionSettings(max_tokens=800, temperature=0.2) # Low temp for precision\n",
    "    \n",
    "    try:\n",
    "        response = await chat_service.get_chat_message_contents(\n",
    "            chat_history=history,\n",
    "            settings=settings\n",
    "        )\n",
    "        print(\"🏛️ SEMANTIC AGENT RESPONSE:\\n\")\n",
    "        print(response[0].content)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "\n",
    "await semantic_phd_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
