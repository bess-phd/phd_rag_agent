{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cdab5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-identity in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.26.0b1)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-identity) (1.38.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-identity) (46.0.3)\n",
      "Requirement already satisfied: msal>=1.30.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-identity) (1.35.0b1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-identity) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from azure-identity) (4.15.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in /home/codespace/.local/lib/python3.12/site-packages (from azure-core>=1.31.0->azure-identity) (2.32.5)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity) (2.23)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity) (2.10.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# 1️⃣ Install / Import Packages\n",
    "# =============================================\n",
    "!pip install --pre azure-ai-projects>=2.0.0b1\n",
    "!pip install azure-identity\n",
    "\n",
    "import os\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "851e13e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DefaultAzureCredential failed to retrieve a token from the included credentials.\n",
      "Attempted credentials:\n",
      "\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\n",
      "Visit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.\n",
      "\tWorkloadIdentityCredential: WorkloadIdentityCredential authentication unavailable. The workload options are not fully configured. See the troubleshooting guide for more information: https://aka.ms/azsdk/python/identity/workloadidentitycredential/troubleshoot. Missing required arguments: 'tenant_id', 'client_id', 'token_file_path'.\n",
      "\tManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no response from the IMDS endpoint. Token request error: (invalid_request) Identity not found\n",
      "\tSharedTokenCacheCredential: SharedTokenCacheCredential authentication unavailable. No accounts were found in the cache.\n",
      "\tVisualStudioCodeCredential: VisualStudioCodeCredential requires the 'azure-identity-broker' package to be installed. You must also ensure you have the Azure Resources extension installed and have signed in to Azure via Visual Studio Code.\n",
      "\tAzureCliCredential: Please run 'az login' to set up an account\n",
      "\tAzurePowerShellCredential: PowerShell is not installed\n",
      "\tAzureDeveloperCliCredential: Azure Developer CLI could not be found. Please visit https://aka.ms/azure-dev for installation instructions and then,once installed, authenticate to your Azure account using 'azd auth login'.\n",
      "\tBrokerCredential: InteractiveBrowserBrokerCredential unavailable. The 'azure-identity-broker' package is required to use brokered authentication.\n",
      "To mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.\n"
     ]
    },
    {
     "ename": "ClientAuthenticationError",
     "evalue": "DefaultAzureCredential failed to retrieve a token from the included credentials.\nAttempted credentials:\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\nVisit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.\n\tWorkloadIdentityCredential: WorkloadIdentityCredential authentication unavailable. The workload options are not fully configured. See the troubleshooting guide for more information: https://aka.ms/azsdk/python/identity/workloadidentitycredential/troubleshoot. Missing required arguments: 'tenant_id', 'client_id', 'token_file_path'.\n\tManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no response from the IMDS endpoint. Token request error: (invalid_request) Identity not found\n\tSharedTokenCacheCredential: SharedTokenCacheCredential authentication unavailable. No accounts were found in the cache.\n\tVisualStudioCodeCredential: VisualStudioCodeCredential requires the 'azure-identity-broker' package to be installed. You must also ensure you have the Azure Resources extension installed and have signed in to Azure via Visual Studio Code.\n\tAzureCliCredential: Please run 'az login' to set up an account\n\tAzurePowerShellCredential: PowerShell is not installed\n\tAzureDeveloperCliCredential: Azure Developer CLI could not be found. Please visit https://aka.ms/azure-dev for installation instructions and then,once installed, authenticate to your Azure account using 'azd auth login'.\n\tBrokerCredential: InteractiveBrowserBrokerCredential unavailable. The 'azure-identity-broker' package is required to use brokered authentication.\nTo mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientAuthenticationError\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mazure\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01midentity\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DefaultAzureCredential\n\u001b[32m      3\u001b[39m cred = DefaultAzureCredential()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m token = \u001b[43mcred\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_token\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://management.azure.com/.default\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mToken acquired:\u001b[39m\u001b[33m\"\u001b[39m, token.token[:\u001b[32m20\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# prints first 20 chars\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/azure/identity/_credentials/default.py:344\u001b[39m, in \u001b[36mDefaultAzureCredential.get_token\u001b[39m\u001b[34m(self, claims, tenant_id, *scopes, **kwargs)\u001b[39m\n\u001b[32m    342\u001b[39m within_dac.set(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     token = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclaims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclaims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    346\u001b[39m     within_dac.set(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/azure/identity/_credentials/chained.py:159\u001b[39m, in \u001b[36mChainedTokenCredential.get_token\u001b[39m\u001b[34m(self, claims, tenant_id, enable_cae, *scopes, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m message = (\n\u001b[32m    152\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\n\u001b[32m    153\u001b[39m     + \u001b[33m\"\u001b[39m\u001b[33m failed to retrieve a token from the included credentials.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttps://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m )\n\u001b[32m    158\u001b[39m _LOGGER.warning(message)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ClientAuthenticationError(message=message)\n",
      "\u001b[31mClientAuthenticationError\u001b[39m: DefaultAzureCredential failed to retrieve a token from the included credentials.\nAttempted credentials:\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\nVisit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.\n\tWorkloadIdentityCredential: WorkloadIdentityCredential authentication unavailable. The workload options are not fully configured. See the troubleshooting guide for more information: https://aka.ms/azsdk/python/identity/workloadidentitycredential/troubleshoot. Missing required arguments: 'tenant_id', 'client_id', 'token_file_path'.\n\tManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no response from the IMDS endpoint. Token request error: (invalid_request) Identity not found\n\tSharedTokenCacheCredential: SharedTokenCacheCredential authentication unavailable. No accounts were found in the cache.\n\tVisualStudioCodeCredential: VisualStudioCodeCredential requires the 'azure-identity-broker' package to be installed. You must also ensure you have the Azure Resources extension installed and have signed in to Azure via Visual Studio Code.\n\tAzureCliCredential: Please run 'az login' to set up an account\n\tAzurePowerShellCredential: PowerShell is not installed\n\tAzureDeveloperCliCredential: Azure Developer CLI could not be found. Please visit https://aka.ms/azure-dev for installation instructions and then,once installed, authenticate to your Azure account using 'azd auth login'.\n\tBrokerCredential: InteractiveBrowserBrokerCredential unavailable. The 'azure-identity-broker' package is required to use brokered authentication.\nTo mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot."
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "cred = DefaultAzureCredential()\n",
    "token = cred.get_token(\"https://management.azure.com/.default\")\n",
    "print(\"Token acquired:\", token.token[:20], \"...\")  # prints first 20 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a7299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved agent: UKEF1\n",
      "Q: Explain coverage rules for UKEF projects.\n",
      "A: Simulated fallback: Coverage applies to low-risk projects up to £5M.\n",
      "--------------------------------------------------------------------------------\n",
      "Q: Summarize key points of my PhD methodology.\n",
      "A: PhD Agent simulated answer:\n",
      "Context:\n",
      "This is a sample PhD methodology document covering experiments and analysis.\n",
      "Question:\n",
      "Summarize key points of my PhD methodology.\n",
      "--------------------------------------------------------------------------------\n",
      "Q: How does the No Net Cost mandate apply?\n",
      "A: The 'No Net Cost' mandate requires UKEF to operate so that its long-term financial operations do not create a loss for HM Treasury. (Source: UKEF 'No Net Cost' mandate)\n",
      "--------------------------------------------------------------------------------\n",
      "Q: What is the maximum project risk we can cover?\n",
      "A: Not found in the documents.\n",
      "---\n",
      "PhD Agent simulated answer:\n",
      "Context:\n",
      "This is a sample PhD methodology document covering experiments and analysis.\n",
      "Question:\n",
      "What is the maximum project risk we can cover?\n",
      "---\n",
      "Finance Agent simulated answer:\n",
      "Context:\n",
      "Finance Agent docs: budgets, risk analysis, and cash flows.\n",
      "Question:\n",
      "What is the maximum project risk we can cover?\n",
      "--------------------------------------------------------------------------------\n",
      "Q: Provide budget insights for low-risk projects.\n",
      "A: Finance Agent simulated answer:\n",
      "Context:\n",
      "Finance Agent docs: budgets, risk analysis, and cash flows.\n",
      "Question:\n",
      "Provide budget insights for low-risk projects.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# =============================================\n",
    "# 2️⃣ Define UKEF Agent (Live Azure Option)\n",
    "# =============================================\n",
    "USE_AZURE_AGENT = True  # Set False to use simulated UKEF agent\n",
    "\n",
    "if USE_AZURE_AGENT:\n",
    "    myEndpoint = \"\"\n",
    "    project_client = AIProjectClient(\n",
    "        endpoint=myEndpoint,\n",
    "        credential=DefaultAzureCredential(),\n",
    "    )\n",
    "    myAgent = \"UKEF1\"\n",
    "    agent = project_client.agents.get(agent_name=myAgent)\n",
    "    print(f\"Retrieved agent: {agent.name}\")\n",
    "    openai_client = project_client.get_openai_client()\n",
    "\n",
    "    def ask_ukef_agent(question):\n",
    "        try:\n",
    "            resp = openai_client.responses.create(\n",
    "                input=[{\"role\": \"user\", \"content\": question}],\n",
    "                extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "            )\n",
    "            answer = resp.output_text\n",
    "            if not answer.strip():\n",
    "                return \"Simulated fallback: Coverage applies to low-risk projects up to £5M.\"\n",
    "            return answer\n",
    "        except Exception:\n",
    "            return \"Simulated fallback: Coverage applies to low-risk projects up to £5M.\"\n",
    "else:\n",
    "    def ask_ukef_agent(question):\n",
    "        return \"Simulated fallback: Coverage applies to low-risk projects up to £5M.\"\n",
    "\n",
    "# =============================================\n",
    "# 3️⃣ Define PhD Agent (Simulated / Local RAG)\n",
    "# =============================================\n",
    "def ask_phd_agent(question):\n",
    "    folder = \"data_phd\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "        with open(f\"{folder}/doc1.txt\", \"w\") as f:\n",
    "            f.write(\"This is a sample PhD methodology document covering experiments and analysis.\")\n",
    "    \n",
    "    docs = [open(f\"{folder}/{f}\").read() for f in os.listdir(folder) if f.endswith(\".txt\")]\n",
    "    context = \"\\n\".join(docs)\n",
    "    return f\"PhD Agent simulated answer:\\nContext:\\n{context}\\nQuestion:\\n{question}\"\n",
    "\n",
    "# =============================================\n",
    "# 4️⃣ Define Finance Agent (Simulated)\n",
    "# =============================================\n",
    "def ask_finance_agent(question):\n",
    "    folder = \"data_finance\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "        with open(f\"{folder}/doc1.txt\", \"w\") as f:\n",
    "            f.write(\"Finance Agent docs: budgets, risk analysis, and cash flows.\")\n",
    "    \n",
    "    docs = [open(f\"{folder}/{f}\").read() for f in os.listdir(folder) if f.endswith(\".txt\")]\n",
    "    context = \"\\n\".join(docs)\n",
    "    return f\"Finance Agent simulated answer:\\nContext:\\n{context}\\nQuestion:\\n{question}\"\n",
    "\n",
    "# =============================================\n",
    "# 5️⃣ Orchestrator Agent\n",
    "# =============================================\n",
    "def orchestrator_agent(question):\n",
    "    \"\"\"\n",
    "    Orchestrator = agent itself\n",
    "    Routes queries to child agents and aggregates responses\n",
    "    \"\"\"\n",
    "    q = question.lower()\n",
    "    if \"ukef\" in q or \"coverage\" in q or \"mandate\" in q:\n",
    "        return ask_ukef_agent(question)\n",
    "    elif \"phd\" in q or \"research\" in q or \"methodology\" in q:\n",
    "        return ask_phd_agent(question)\n",
    "    elif \"finance\" in q or \"budget\" in q:\n",
    "        return ask_finance_agent(question)\n",
    "    else:\n",
    "        # Call all agents and aggregate\n",
    "        resp1 = ask_ukef_agent(question)\n",
    "        resp2 = ask_phd_agent(question)\n",
    "        resp3 = ask_finance_agent(question)\n",
    "        return f\"{resp1}\\n---\\n{resp2}\\n---\\n{resp3}\"\n",
    "\n",
    "# =============================================\n",
    "# 6️⃣ Example Queries / Demo\n",
    "# =============================================\n",
    "example_questions = [\n",
    "    \"Explain coverage rules for UKEF projects.\",\n",
    "    \"Summarize key points of my PhD methodology.\",\n",
    "    \"How does the No Net Cost mandate apply?\",\n",
    "    \"What is the maximum project risk we can cover?\",\n",
    "    \"Provide budget insights for low-risk projects.\"\n",
    "]\n",
    "\n",
    "for q in example_questions:\n",
    "    print(\"Q:\", q)\n",
    "    print(\"A:\", orchestrator_agent(q))\n",
    "    print(\"-\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2186c396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting semantic-kernel\n",
      "  Downloading semantic_kernel-1.39.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: azure-identity in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.26.0b1)\n",
      "Requirement already satisfied: openai in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.15.0)\n",
      "Collecting azure-ai-projects~=1.0.0b12 (from semantic-kernel)\n",
      "  Downloading azure_ai_projects-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting azure-ai-agents>=1.2.0b3 (from semantic-kernel)\n",
      "  Downloading azure_ai_agents-1.2.0b6-py3-none-any.whl.metadata (74 kB)\n",
      "Collecting aiohttp~=3.8 (from semantic-kernel)\n",
      "  Downloading aiohttp-3.13.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting cloudevents~=1.0 (from semantic-kernel)\n",
      "  Downloading cloudevents-1.12.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0 (from semantic-kernel)\n",
      "  Downloading pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting pydantic-settings~=2.0 (from semantic-kernel)\n",
      "  Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: defusedxml~=0.7 in /home/codespace/.local/lib/python3.12/site-packages (from semantic-kernel) (0.7.1)\n",
      "Collecting numpy>=1.26.0 (from semantic-kernel)\n",
      "  Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting openapi_core<0.20,>=0.18 (from semantic-kernel)\n",
      "  Downloading openapi_core-0.19.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting websockets<16,>=13 (from semantic-kernel)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting aiortc>=1.9.0 (from semantic-kernel)\n",
      "  Downloading aiortc-1.14.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting opentelemetry-api~=1.24 (from semantic-kernel)\n",
      "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-sdk~=1.24 (from semantic-kernel)\n",
      "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting prance<25.4.9,>=23.6.21 (from semantic-kernel)\n",
      "  Downloading prance-25.4.8.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pybars4~=0.9 (from semantic-kernel)\n",
      "  Downloading pybars4-0.9.13.tar.gz (29 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jinja2~=3.1 in /home/codespace/.local/lib/python3.12/site-packages (from semantic-kernel) (3.1.6)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in /home/codespace/.local/lib/python3.12/site-packages (from semantic-kernel) (1.6.0)\n",
      "Collecting scipy>=1.15.1 (from semantic-kernel)\n",
      "  Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting protobuf (from semantic-kernel)\n",
      "  Downloading protobuf-6.33.4-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: typing-extensions>=4.13 in /home/codespace/.local/lib/python3.12/site-packages (from semantic-kernel) (4.15.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp~=3.8->semantic-kernel) (25.4.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-ai-projects~=1.0.0b12->semantic-kernel) (0.7.2)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-ai-projects~=1.0.0b12->semantic-kernel) (1.38.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.15.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-ai-projects~=1.0.0b12->semantic-kernel) (12.28.0)\n",
      "Collecting deprecation<3.0,>=2.0 (from cloudevents~=1.0->semantic-kernel)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from deprecation<3.0,>=2.0->cloudevents~=1.0->semantic-kernel) (25.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2~=3.1->semantic-kernel) (3.0.3)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /home/codespace/.local/lib/python3.12/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.25.1)\n",
      "Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting more-itertools (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading openapi_schema_validator-0.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading openapi_spec_validator-0.7.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting parse (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting werkzeug<3.1.2 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading werkzeug-3.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.29.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (6.0.3)\n",
      "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (2.32.5)\n",
      "Requirement already satisfied: rfc3339-validator in /home/codespace/.local/lib/python3.12/site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.1.4)\n",
      "Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api~=1.24->semantic-kernel)\n",
      "  Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk~=1.24->semantic-kernel)\n",
      "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting chardet>=5.2 (from prance<25.4.9,>=23.6.21->semantic-kernel)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting ruamel.yaml>=0.18.10 (from prance<25.4.9,>=23.6.21->semantic-kernel)\n",
      "  Downloading ruamel_yaml-0.19.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting PyMeta3>=0.5.1 (from pybars4~=0.9->semantic-kernel)\n",
      "  Downloading PyMeta3-0.5.1.tar.gz (29 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.7.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.4.2)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings~=2.0->semantic-kernel)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (2.5.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-identity) (46.0.3)\n",
      "Requirement already satisfied: msal>=1.30.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-identity) (1.35.0b1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from azure-identity) (1.3.1)\n",
      "Collecting aioice<1.0.0,>=0.10.1 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading aioice-0.10.2-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting av<17.0.0,>=14.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading av-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting google-crc32c>=1.1 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading google_crc32c-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting pyee>=13.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pylibsrtp>=0.10.0 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading pylibsrtp-1.0.0-cp310-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting pyopenssl>=25.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading pyopenssl-25.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting dnspython>=2.0.0 (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting ifaddr>=0.2.0 (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel)\n",
      "  Downloading ifaddr-0.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity) (2.23)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity) (2.10.1)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.12/site-packages (from rfc3339-validator->openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel) (1.17.0)\n",
      "Downloading semantic_kernel-1.39.2-py3-none-any.whl (910 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m910.9/910.9 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.13.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_ai_projects-1.0.0-py3-none-any.whl (115 kB)\n",
      "Downloading cloudevents-1.12.0-py3-none-any.whl (55 kB)\n",
      "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Downloading openapi_core-0.19.5-py3-none-any.whl (106 kB)\n",
      "Downloading jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n",
      "Downloading openapi_schema_validator-0.6.3-py3-none-any.whl (8.8 kB)\n",
      "Downloading openapi_spec_validator-0.7.2-py3-none-any.whl (39 kB)\n",
      "Downloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "Downloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
      "Downloading importlib_metadata-8.7.1-py3-none-any.whl (27 kB)\n",
      "Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
      "Downloading pathable-0.4.4-py3-none-any.whl (9.6 kB)\n",
      "Downloading prance-25.4.8.0-py3-none-any.whl (36 kB)\n",
      "Downloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Downloading werkzeug-3.1.1-py3-none-any.whl (224 kB)\n",
      "Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiortc-1.14.0-py3-none-any.whl (93 kB)\n",
      "Downloading aioice-0.10.2-py3-none-any.whl (24 kB)\n",
      "Downloading av-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading azure_ai_agents-1.2.0b6-py3-none-any.whl (217 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
      "Downloading google_crc32c-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (33 kB)\n",
      "Downloading ifaddr-0.2.0-py3-none-any.whl (12 kB)\n",
      "Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
      "Downloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
      "Downloading pylibsrtp-1.0.0-cp310-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyopenssl-25.3.0-py3-none-any.whl (57 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading ruamel_yaml-0.19.1-py3-none-any.whl (118 kB)\n",
      "Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (35.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
      "Downloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
      "Downloading protobuf-6.33.4-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Building wheels for collected packages: pybars4, PyMeta3\n",
      "  Building wheel for pybars4 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pybars4: filename=pybars4-0.9.13-py3-none-any.whl size=14418 sha256=452ff0cf071335a73e16f23ad963645d75cf28911d67d9d74a55c3e357aeb765\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/75/2d/da/c75b2fc7b00dc9c154dff65f689a318e7d24b44c612c2b21f1\n",
      "  Building wheel for PyMeta3 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyMeta3: filename=pymeta3-0.5.1-py3-none-any.whl size=16519 sha256=b7d39abb314e6d26385beca37abba8b9d0bd7065755306a5517cab174d1c27ac\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/5a/9b/2c/81b7551d2c05a482817e6c3b3d2f8ad2a0229db874c4bc6346\n",
      "Successfully built pybars4 PyMeta3\n",
      "Installing collected packages: PyMeta3, parse, ifaddr, zipp, werkzeug, websockets, ruamel.yaml, referencing, python-dotenv, pyee, pydantic-core, pybars4, protobuf, propcache, pathable, numpy, multidict, more-itertools, lazy-object-proxy, google-crc32c, frozenlist, dnspython, deprecation, chardet, av, aiohappyeyeballs, yarl, scipy, pylibsrtp, pydantic, prance, jsonschema-path, importlib-metadata, cloudevents, aiosignal, aioice, pyopenssl, pydantic-settings, opentelemetry-api, openai, azure-ai-agents, aiohttp, opentelemetry-semantic-conventions, openapi-schema-validator, azure-ai-projects, aiortc, opentelemetry-sdk, openapi-spec-validator, openapi_core, semantic-kernel\n",
      "\u001b[2K  Attempting uninstall: referencing━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/50\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K    Found existing installation: referencing 0.37.0━━━━━━━━━━━\u001b[0m \u001b[32m 6/50\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K    Uninstalling referencing-0.37.0:━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/50\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K      Successfully uninstalled referencing-0.37.0━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/50\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K  Attempting uninstall: pydantic-core━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/50\u001b[0m [referencing]\n",
      "\u001b[2K    Found existing installation: pydantic_core 2.41.5━━━━━━━━━\u001b[0m \u001b[32m 7/50\u001b[0m [referencing]\n",
      "\u001b[2K    Uninstalling pydantic_core-2.41.5:━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/50\u001b[0m [referencing]\n",
      "\u001b[2K      Successfully uninstalled pydantic_core-2.41.5━━━━━━━━━━━\u001b[0m \u001b[32m 7/50\u001b[0m [referencing]\n",
      "\u001b[2K  Attempting uninstall: pydanticm\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/50\u001b[0m [scipy]t]n]\n",
      "\u001b[2K    Found existing installation: pydantic 2.12.5━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/50\u001b[0m [scipy]\n",
      "\u001b[2K    Uninstalling pydantic-2.12.5:m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/50\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.12.5━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/50\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: openai━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m37/50\u001b[0m [pydantic-settings]\n",
      "\u001b[2K    Found existing installation: openai 2.15.0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m37/50\u001b[0m [pydantic-settings]\n",
      "\u001b[2K    Uninstalling openai-2.15.0:━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m39/50\u001b[0m [openai]ttings]\n",
      "\u001b[2K      Successfully uninstalled openai-2.15.0╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m39/50\u001b[0m [openai]\n",
      "\u001b[2K  Attempting uninstall: azure-ai-projects[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m42/50\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K    Found existing installation: azure-ai-projects 2.0.0b30m \u001b[32m42/50\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K    Uninstalling azure-ai-projects-2.0.0b3:[0m\u001b[90m━━━━━\u001b[0m \u001b[32m42/50\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K      Successfully uninstalled azure-ai-projects-2.0.0b3\u001b[0m \u001b[32m42/50\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/50\u001b[0m [semantic-kernel]c-kernel]_core]validator]s]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PyMeta3-0.5.1 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aioice-0.10.2 aiortc-1.14.0 aiosignal-1.4.0 av-16.1.0 azure-ai-agents-1.2.0b6 azure-ai-projects-1.0.0 chardet-5.2.0 cloudevents-1.12.0 deprecation-2.1.0 dnspython-2.8.0 frozenlist-1.8.0 google-crc32c-1.8.0 ifaddr-0.2.0 importlib-metadata-8.7.1 jsonschema-path-0.3.4 lazy-object-proxy-1.12.0 more-itertools-10.8.0 multidict-6.7.0 numpy-2.4.1 openai-1.109.1 openapi-schema-validator-0.6.3 openapi-spec-validator-0.7.2 openapi_core-0.19.5 opentelemetry-api-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 parse-1.20.2 pathable-0.4.4 prance-25.4.8.0 propcache-0.4.1 protobuf-6.33.4 pybars4-0.9.13 pydantic-2.11.10 pydantic-core-2.33.2 pydantic-settings-2.12.0 pyee-13.0.0 pylibsrtp-1.0.0 pyopenssl-25.3.0 python-dotenv-1.2.1 referencing-0.36.2 ruamel.yaml-0.19.1 scipy-1.17.0 semantic-kernel-1.39.2 websockets-15.0.1 werkzeug-3.1.1 yarl-1.22.0 zipp-3.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install semantic-kernel azure-identity openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2296bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install semantic-kernel azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f57107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "kernel = sk.Kernel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "581f2688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPlugin(name='PhD', description=None, functions={'PhDAgent': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='PhDAgent', plugin_name='PhD', description='Handles academic methodology, research experiments, and thesis evaluation.', parameters=[KernelParameterMetadata(name='query', description=None, default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True)], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x77f5ddf5dd60>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x77f5de781a60>, method=<bound method PhDPlugin.get_research of <__main__.PhDPlugin object at 0x77f5de7810a0>>, stream_method=None)})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Define Native Plugins ---\n",
    "\n",
    "class UKEFPlugin:\n",
    "    @kernel_function(\n",
    "        name=\"UKEFAgent\",\n",
    "        description=\"Provides policy coverage details and financial limits for UKEF projects.\"\n",
    "    )\n",
    "    def get_coverage(self, query: str) -> str:\n",
    "        # This is where your CSV-reading logic would live\n",
    "        return \"UKEF policy coverage applies to low-risk projects up to £5M.\"\n",
    "\n",
    "class PhDPlugin:\n",
    "    @kernel_function(\n",
    "        name=\"PhDAgent\",\n",
    "        description=\"Handles academic methodology, research experiments, and thesis evaluation.\"\n",
    "    )\n",
    "    def get_research(self, query: str) -> str:\n",
    "        return \"PhD agent: Specialized in methodology and systematic evaluation.\"\n",
    "\n",
    "# --- Register Plugins ---\n",
    "kernel.add_plugin(UKEFPlugin(), plugin_name=\"UKEF\")\n",
    "kernel.add_plugin(PhDPlugin(), plugin_name=\"PhD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44920f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings\n",
    "\n",
    "async def agentic_orchestrator(query: str):\n",
    "    # Set behavior to automatically call functions (plugins)\n",
    "    settings = AzureChatPromptExecutionSettings(\n",
    "        function_choice_behavior=FunctionChoiceBehavior.Auto()\n",
    "    )\n",
    "    \n",
    "    # We use invoke_prompt. The LLM sees the description of UKEFAgent and PhDAgent\n",
    "    # and decides which one to call based on the user's intent.\n",
    "    result = await kernel.invoke_prompt(\n",
    "        function_name=\"Orchestrator\",\n",
    "        plugin_name=\"Main\",\n",
    "        prompt=query,\n",
    "        settings=settings\n",
    "    )\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f49bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: The 'Clean Slate' approach (Recommended for Notebooks)\n",
    "#kernel.remove_all_services()\n",
    "\n",
    "# Now add your fixed service with the token_provider\n",
    "#kernel.add_service(azure_chat)\n",
    "\n",
    "# Option 2: The 'Overwrite' approach\n",
    "# kernel.add_service(azure_chat, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8ce561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# 1. Create the credential\n",
    "cred = DefaultAzureCredential()\n",
    "\n",
    "# 2. CREATE A TOKEN PROVIDER with the correct 'Cognitive Services' scope\n",
    "# This is the \"Magic Sauce\" that fixes the 401 Audience error\n",
    "token_provider = get_bearer_token_provider(\n",
    "    cred, \n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "\n",
    "# 3. Initialize AzureChatCompletion using the token_provider\n",
    "azure_chat = AzureChatCompletion(\n",
    "    deployment_name=\"gpt-4o\",\n",
    "    endpoint=myEndpoint,\n",
    "    ad_token_provider=token_provider # Use this instead of passing 'cred' directly\n",
    ")\n",
    "\n",
    "kernel.add_service(azure_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bca08e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Kernel initialized from scratch. No conflicts!\n"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "\n",
    "# 1. Complete Kernel Reset\n",
    "kernel = sk.Kernel() \n",
    "\n",
    "# 2. Add the service with the fixed token provider\n",
    "# (Make sure azure_chat is already defined with ad_token_provider)\n",
    "kernel.add_service(azure_chat)\n",
    "\n",
    "# 3. Re-register Plugins (This overwrites anything old)\n",
    "# We don't need to \"remove\" them because we made a 'new' kernel above\n",
    "kernel.add_plugin(UKEFPlugin(), plugin_name=\"UKEF\")\n",
    "kernel.add_plugin(PhDPlugin(), plugin_name=\"PhD\")\n",
    "\n",
    "print(\"✅ Kernel initialized from scratch. No conflicts!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66b853b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "# 1. Create the credential as before\n",
    "cred = DefaultAzureCredential()\n",
    "\n",
    "# 2. CREATE A TOKEN PROVIDER with the specific scope for AI services\n",
    "# This specifically fixes the \"audience is incorrect\" error.\n",
    "token_provider = get_bearer_token_provider(\n",
    "    cred, \n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "\n",
    "# 3. Update your AzureChatCompletion to use 'ad_token_provider'\n",
    "azure_chat = AzureChatCompletion(\n",
    "    deployment_name=\"gpt-4o\",\n",
    "    endpoint=myEndpoint,\n",
    "    ad_token_provider=token_provider  # Use the provider, not the raw credential\n",
    ")\n",
    "\n",
    "# 4. Clean and re-add the service to avoid the \"Already Exists\" error\n",
    "kernel.remove_all_services()\n",
    "kernel.add_service(azure_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65eb0e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ System fully reset with cleaned endpoint and stable API version.\n"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "# --- 1. CLEAN YOUR ENDPOINT ---\n",
    "# Ensure myEndpoint is ONLY: https://your-resource-name.openai.azure.com/\n",
    "# (No trailing slashes, no /openai/ path)\n",
    "clean_endpoint = myEndpoint.split(\"/openai/\")[0].strip(\"/\")\n",
    "\n",
    "# --- 2. SETUP IDENTITY ---\n",
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(), \n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "\n",
    "# --- 3. INITIALIZE SERVICE WITH STABLE API VERSION ---\n",
    "azure_chat = AzureChatCompletion(\n",
    "    deployment_name=\"gpt-4o\",\n",
    "    endpoint=clean_endpoint,\n",
    "    ad_token_provider=token_provider,\n",
    "    api_version=\"2024-05-01-preview\" # Using a guaranteed stable version\n",
    ")\n",
    "\n",
    "# --- 4. CLEAN RESET ---\n",
    "kernel = sk.Kernel()\n",
    "kernel.add_service(azure_chat)\n",
    "\n",
    "# --- 5. RE-REGISTER PLUGINS ---\n",
    "# Ensure these classes are defined in your notebook!\n",
    "kernel.add_plugin(UKEFPlugin(), plugin_name=\"UKEF\")\n",
    "kernel.add_plugin(PhDPlugin(), plugin_name=\"PhD\")\n",
    "\n",
    "print(\"✅ System fully reset with cleaned endpoint and stable API version.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc98c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# Test if your environment can even \"see\" the endpoint\n",
    "try:\n",
    "    response = requests.get(clean_endpoint)\n",
    "    print(f\"Network Check: Connection successful (Status: {response.status_code})\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Network Check Failed: Your firewall or VPN is blocking the connection. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ae795f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scope MUST be cognitiveservices, not ai.azure.com\n",
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(), \n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a52cbad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_info = cred.get_token(\"https://cognitiveservices.azure.com/.default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d4ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        deployment_name=\"gpt-4o\",  # must match the deployment in abphd\n",
    "        endpoint=\"/\",  # ✅ base endpoint\n",
    "        api_key=\"\"  # ✅ use Key1\n",
    "    ),\n",
    "    overwrite=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6c543e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing agents: ['agent_ukef', 'agent_phd']\n"
     ]
    }
   ],
   "source": [
    "existing_agents = [name for name in [\"agent_ukef\", \"agent_phd\"] if name in globals()]\n",
    "print(\"Existing agents:\", existing_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 GPT-4o-Mini Response:\n",
      "\n",
      "The UKEF (UK Export Finance) 'No Net Cost' mandate is considered a 'solvency-based constraint' for a PhD methodology because it requires that any financial support or guarantees provided by UKEF must not result in a net loss to the government. This means that the financial viability and sustainability of projects must be assessed in a way that ensures the expected revenues or benefits will at least cover the costs associated with the support provided.\n",
      "\n",
      "In the context of a PhD methodology, this constraint necessitates a rigorous evaluation of the economic impacts, risks, and financial models associated with the research. Researchers must demonstrate that their proposed projects are not only feasible but also financially sound, ensuring that they can achieve a positive net outcome. This focus on solvency influences the design of the research, the selection of case studies, and the analytical frameworks used, as the methodology must align with the principles of financial prudence and accountability mandated by UKEF.\n"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIPromptExecutionSettings\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# Updated for gpt-4o-mini\n",
    "chat_service = AzureChatCompletion(\n",
    "    deployment_name=\"gpt-4o-mini\",  # Make sure this matches your Azure Deployment Name\n",
    "    endpoint=\"\",\n",
    "    api_key=\"\",\n",
    "    api_version=\"2024-08-01-preview\" # Updated to a version that fully supports mini's features\n",
    ")\n",
    "\n",
    "kernel.add_service(chat_service)\n",
    "\n",
    "async def test_mini_chat():\n",
    "    history = ChatHistory()\n",
    "    history.add_user_message(\"Briefly explain why the UKEF 'No Net Cost' mandate is a 'solvency-based constraint' for a PhD methodology.\")\n",
    "    \n",
    "    # We use a lower temperature (0.3) for more \"academic\" and precise results\n",
    "    settings = OpenAIPromptExecutionSettings(max_tokens=500, temperature=0.3)\n",
    "    \n",
    "    try:\n",
    "        response = await chat_service.get_chat_message_contents(\n",
    "            chat_history=history,\n",
    "            settings=settings\n",
    "        )\n",
    "        print(\"🤖 GPT-4o-Mini Response:\\n\")\n",
    "        print(response[0].content)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "\n",
    "await test_mini_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "385bd59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏛️ SEMANTIC AGENT RESPONSE:\n",
      "\n",
      "The No Net Cost mandate serves as a critical solvency-based constraint within the context of financial management and economic policy, particularly in the realm of public financing and investment. This mandate stipulates that any financial initiative or project must be designed and executed in such a manner that it does not incur a net cost to the public treasury. In essence, it requires that the financial outlays associated with a project be offset by corresponding revenues or savings, thereby ensuring that the fiscal integrity of the governing body remains intact.\n",
      "\n",
      "From a methodological perspective, the No Net Cost mandate necessitates a rigorous assessment of both the costs and benefits associated with any proposed initiative. This aligns with the principles articulated by Koomey (2011), who emphasizes the importance of efficiency in resource allocation and the need for a comprehensive evaluation of the economic implications of energy-related investments. By adhering to the No Net Cost principle, researchers and policymakers are compelled to adopt a holistic approach to financial analysis, ensuring that all potential revenue streams and cost-saving measures are thoroughly explored and integrated into the project design.\n",
      "\n",
      "Moreover, the application of this mandate can be further elucidated through the lens of Grootendorst (2022), who discusses the implications of financial constraints on project viability and sustainability. The No Net Cost mandate not only serves as a fiscal guideline but also acts as a catalyst for innovation, prompting stakeholders to seek out creative financing solutions and partnerships that can enhance the overall value proposition of a project.\n",
      "\n",
      "In summary, the No Net Cost mandate functions as a solvency-based constraint that requires a meticulous evaluation of financial flows associated with public projects. By ensuring that expenditures are balanced by revenues, this mandate fosters fiscal responsibility and encourages the pursuit of efficiency, ultimately contributing to the sustainability of public finance.\n"
     ]
    }
   ],
   "source": [
    "async def semantic_phd_chat():\n",
    "    history = ChatHistory()\n",
    "    \n",
    "    # 1. THE SEMANTIC \"PERSONA\": This makes it a specialized agent\n",
    "    history.add_system_message(\"\"\"\n",
    "    You are the 'UKEF-PhD Bridge Agent'. Your goal is to help the user integrate \n",
    "    financial mandates into academic research methodology. \n",
    "    \n",
    "    CRITICAL CONSTRAINTS:\n",
    "    - Focus on the 'No Net Cost' mandate as a 'solvency-based constraint'.\n",
    "    - Use formal academic language.\n",
    "    - References to prioritize: Koomey (2011) for efficiency and Grootendorst (2022).\n",
    "    \"\"\")\n",
    "    \n",
    "    # 2. THE USER QUERY\n",
    "    history.add_user_message(\"Explain the No Net Cost mandate as a solvency-based constraint.\")\n",
    "    \n",
    "    settings = OpenAIPromptExecutionSettings(max_tokens=800, temperature=0.2) # Low temp for precision\n",
    "    \n",
    "    try:\n",
    "        response = await chat_service.get_chat_message_contents(\n",
    "            chat_history=history,\n",
    "            settings=settings\n",
    "        )\n",
    "        print(\"🏛️ SEMANTIC AGENT RESPONSE:\\n\")\n",
    "        print(response[0].content)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "\n",
    "await semantic_phd_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
